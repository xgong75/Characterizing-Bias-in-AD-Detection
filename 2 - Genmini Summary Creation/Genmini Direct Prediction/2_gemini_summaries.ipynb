{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1746150376880,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "QLteybcQ1qXp"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1446,
     "status": "ok",
     "timestamp": 1746150380161,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "roy8ljV7up98"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import auth, drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1487,
     "status": "ok",
     "timestamp": 1746150382975,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "Pab8NbSxuzEM",
    "outputId": "110dd208-f957-41df-c266-396b3fa62849"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5576,
     "status": "ok",
     "timestamp": 1746150390915,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "tx_Kh5j8u0XM"
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    Image,\n",
    "    Part,\n",
    "    SafetySetting,\n",
    ")\n",
    "from vertexai.batch_prediction import BatchPredictionJob\n",
    "import json\n",
    "from google.cloud import storage\n",
    "\n",
    "# replace with project ID from Google Cloud Platform\n",
    "PROJECT_ID = \"mit-mlhc-v2\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1746150397375,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "qm6ognySu2LV"
   },
   "outputs": [],
   "source": [
    "def extract_text(response):\n",
    "  \"\"\"Extracts text from the response dictionary, handling potential KeyError.\"\"\"\n",
    "  try:\n",
    "    return response['candidates'][0]['content']['parts'][0]['text']\n",
    "  except (KeyError, IndexError, TypeError):\n",
    "    # Handle cases where 'parts' key is missing or empty\n",
    "    print(response)\n",
    "   # Or any other appropriate default value\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746150398232,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "4TXOVOsZ3qGw"
   },
   "outputs": [],
   "source": [
    "def concatenate_notes(group):\n",
    "  return '\\n\\n'.join(f\"{row['hadm_id_long']}\\n{row['summary']}\" for _, row in group.iterrows())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2RvLIFLu8tU"
   },
   "source": [
    "# Summarise Clinical Notes\n",
    "\n",
    "- get summaries from Gemini\n",
    "- merge summaries by subject_id, in order\n",
    "- get second summary from *Gemini*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCsEDJ7Pv5TK"
   },
   "source": [
    "## Regex masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5012,
     "status": "ok",
     "timestamp": 1746150407612,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "_zO_o3XWu89P",
    "outputId": "7f260dd5-718c-45d7-9db7-a19da1e0ab19"
   },
   "outputs": [],
   "source": [
    "fn = '/content/drive/MyDrive/HSPH/Courses/MIT6.7930/AI Bias for AD/AI Bias AD/Gemini Prediction Model/12_regex_masked_concat.csv'\n",
    "df = pd.read_csv(fn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHTewtAt6DVA"
   },
   "source": [
    "### First pass summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 984346,
     "status": "ok",
     "timestamp": 1746119474596,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "kw1C-y6avACj",
    "outputId": "9c13e64a-326d-49f1-ea16-4542ea8bcc65"
   },
   "outputs": [],
   "source": [
    "def df_to_jsonl_gcs(df, bucket_name, blob_name):\n",
    "    \"\"\"Converts a DataFrame to JSONL and uploads to Google Cloud Storage.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame with a 'text' column.\n",
    "        bucket_name: Name of your Google Cloud Storage bucket.\n",
    "        blob_name: Desired name for the JSONL file on GCS.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a GCS client\n",
    "    storage_client = storage.Client(project=PROJECT_ID)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    if not bucket.exists():\n",
    "        bucket.create(location='US')\n",
    "        print(f'Bucket {bucket_name} created.')\n",
    "    else:\n",
    "        print(f'Bucket {bucket_name} already exists.')\n",
    "\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Write JSONL data to a string buffer\n",
    "    jsonl_data = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "        ### TO DO: Provide Gemini a prompt ##############################\n",
    "        # Edit the prompt to tell Gemini how to handle your input text\n",
    "        text = row['concatenated_notes']#[:50000]\n",
    "\n",
    "        prompt = f\"\"\"You are a neurologist tasked with providing observations and summaries of clinical notes. Each clinical note corresponds to one hospital admission for a patient. Based on the clinical notes provided, please comment on each of the domains listed below:\n",
    "        1) For cognitive status, describe memory, attention, language, and executive function findings. Please also describe any current sleep patterns and any notable changes in sleep patterns that are documented.\n",
    "        2) For neurological findings, describe the circumstances and results of any motor and sensory tests performed including assessment of reflexes, gait, coordination, and imaging results if mentioned.\n",
    "        3) For functional abilities, describe the patient's level of independence in activities of daily life and any changes from previous status that are noted.\n",
    "        4) For relevant medical history, list comorbidities and chronic conditions, especially ones that may affect cognitive or functional status. Please also describe current symptoms and any treatments received.\n",
    "         Please use precise clinical language suitable for a medical professional audience.\n",
    "        Here are the patient's clinical notes for their hospital stay: {text}\"\"\"\n",
    "        #################################################################\n",
    "\n",
    "        json_data = {\n",
    "            \"id\": row['id'],\n",
    "            \"request\": {\n",
    "                \"contents\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"parts\": [{\"text\": prompt}]\n",
    "                    }\n",
    "                ],\n",
    "                \"generationConfig\": {\"temperature\": 0.4, \"maxOutputTokens\": 2048},\n",
    "\n",
    "            }\n",
    "        }\n",
    "        jsonl_data += json.dumps(json_data) + '\\n'\n",
    "\n",
    "    # Upload the JSONL data to GCS\n",
    "    blob.upload_from_string(jsonl_data, content_type='application/jsonl')\n",
    "    print(f\"JSONL file uploaded to gs://{bucket_name}/{blob_name}\")\n",
    "\n",
    "    return f\"gs://{bucket_name}/{blob_name}\"\n",
    "\n",
    "### TO DO: Change bucket name ##############################\n",
    "\n",
    "BUCKET_NAME = 'project_summary_regex'\n",
    "input_uri = df_to_jsonl_gcs(df, BUCKET_NAME, 'gemini_batch_requests.jsonl')\n",
    "\n",
    "#################################################################\n",
    "\n",
    "output_uri = f\"gs://{BUCKET_NAME}/batch-prediction/\"\n",
    "\n",
    "# Submit a batch prediction job with Gemini model\n",
    "batch_prediction_job = BatchPredictionJob.submit(\n",
    "    source_model=\"gemini-1.5-flash-001\",\n",
    "    input_dataset=input_uri,\n",
    "    output_uri_prefix=output_uri,\n",
    ")\n",
    "\n",
    "# Check job status\n",
    "print(f\"Job resource name: {batch_prediction_job.resource_name}\")\n",
    "print(f\"Model resource name with the job: {batch_prediction_job.model_name}\")\n",
    "print(f\"Job state: {batch_prediction_job.state.name}\")\n",
    "\n",
    "# Refresh the job until complete\n",
    "while not batch_prediction_job.has_ended:\n",
    "    time.sleep(5)\n",
    "    batch_prediction_job.refresh()\n",
    "\n",
    "# Check if the job succeeds\n",
    "if batch_prediction_job.has_succeeded:\n",
    "    print(\"Job succeeded!\")\n",
    "else:\n",
    "    print(f\"Job failed: {batch_prediction_job.error}\")\n",
    "\n",
    "# Check the location of the output\n",
    "print(f\"Job output location: {batch_prediction_job.output_location}\")\n",
    "\n",
    "# Example response:\n",
    "#  Job output location: gs://your-bucket/gen-ai-batch-prediction/prediction-model-year-month-day-hour:minute:second.12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8841,
     "status": "ok",
     "timestamp": 1746150427153,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "4HOjYMcqvI0y",
    "outputId": "0cad6b36-8e9c-4ba2-d31c-a6d095b54f35"
   },
   "outputs": [],
   "source": [
    "# Load the JSONL file into a DataFrame\n",
    "# once you've made your predictions, they should be\n",
    "# stored at your google cloud storage bucket specified by the path\n",
    "# and you should be able to download it from this path\n",
    "path = 'gs://project_summary_regex/batch-prediction/prediction-model-2025-05-01T16:54:53.974046Z'\n",
    "output_path = path + '/predictions.jsonl'\n",
    "\n",
    "summaries_df = pd.read_json(output_path, lines=True)\n",
    "summaries_df = summaries_df.join(pd.json_normalize(summaries_df[\"response\"], \"candidates\"))\n",
    "print(summaries_df.shape)\n",
    "\n",
    "# Note some inputs may not generate predictions due to SAFETY constraints\n",
    "summaries_df['summary'] = summaries_df['response'].apply(extract_text)\n",
    "summaries_df = summaries_df[summaries_df['summary'] != '']\n",
    "summaries_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1746150429210,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "U6fw8Lyg1eoI",
    "outputId": "abf55ce9-e529-4f4d-c5d3-a4810393bd55"
   },
   "outputs": [],
   "source": [
    "summaries_df = summaries_df[['id', 'summary']]\n",
    "summaries_df.columns = ['id_gemini', 'summary']\n",
    "summaries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1746150436430,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "CGybE2gR1psf",
    "outputId": "00b047e1-78e2-4807-a649-3c75ffa55811"
   },
   "outputs": [],
   "source": [
    "df['id_gemini'] = df['id'].str.replace(r'[_-]', '', regex=True).astype(int)\n",
    "df_summs = pd.merge(df, summaries_df, on='id_gemini', how='inner')\n",
    "df_summs[['subject_id', 'hadm_id']] = df_summs['id'].str.split('_', n=1, expand=True)\n",
    "df_summs = df_summs.drop(['id', 'id_gemini', 'concatenated_notes'], axis=1)\n",
    "df_summs = df_summs.sort_values(by=['subject_id', 'admityear', 'admitmonth', 'admitday'])\n",
    "df_summs['hadm_id_long'] = 'Hospital Admittance ID: ' + df_summs['hadm_id']\n",
    "df_concat = df_summs.groupby('subject_id').apply(concatenate_notes).reset_index(name='concatenated_notes')\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1746150441376,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "OOM2txza2zCd",
    "outputId": "b919529b-449e-4d0b-f647-68d73d34f2a2"
   },
   "outputs": [],
   "source": [
    "df_clean = df_summs.copy()\n",
    "df_clean = df_clean.drop(['admityear', 'admitmonth', 'admitday', 'summary', 'hadm_id', 'hadm_id_long'], axis=1)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "df_clean = df_clean[~df_clean.duplicated(subset='subject_id', keep='last')]\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1746150445951,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "lNKyPkLA4XK0",
    "outputId": "fe86432b-b3a6-44e8-f231-5b72bd0c2b7e"
   },
   "outputs": [],
   "source": [
    "df_regex1 = pd.merge(df_clean, df_concat, on='subject_id', how='inner')\n",
    "print(df_regex1.shape)\n",
    "df_regex1['case_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNM1-utz6IAQ"
   },
   "source": [
    "### Second pass summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1670,
     "status": "ok",
     "timestamp": 1746121927013,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "zlxtJet75_jr",
    "outputId": "cfce821f-5ea7-409d-875a-28b3826c7ee3"
   },
   "outputs": [],
   "source": [
    "def df_to_jsonl_gcs(df, bucket_name, blob_name):\n",
    "    \"\"\"Converts a DataFrame to JSONL and uploads to Google Cloud Storage.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame with a 'text' column.\n",
    "        bucket_name: Name of your Google Cloud Storage bucket.\n",
    "        blob_name: Desired name for the JSONL file on GCS.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a GCS client\n",
    "    storage_client = storage.Client(project=PROJECT_ID)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    if not bucket.exists():\n",
    "        bucket.create(location='US')\n",
    "        print(f'Bucket {bucket_name} created.')\n",
    "    else:\n",
    "        print(f'Bucket {bucket_name} already exists.')\n",
    "\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Write JSONL data to a string buffer\n",
    "    jsonl_data = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "        ### TO DO: Provide Gemini a prompt ##############################\n",
    "        # Edit the prompt to tell Gemini how to handle your input text\n",
    "        text = row['concatenated_notes']#[:50000]\n",
    "\n",
    "        prompt = f\"\"\"You are a neurologist tasked with providing a single summary of clinical notes. The clinical notes provided have been summarized for each hospital stay, but we want you to summarize them further so that we have a single summary for each patient. Based on the clinical notes provided, please summarise each of the domains listed below across the visits:\n",
    "        1) For cognitive status, describe memory, attention, language, and executive function findings. Please also describe any current sleep patterns and any notable changes in sleep patterns that are documented.\n",
    "        2) For neurological findings, describe the circumstances and results of any motor and sensory tests performed including assessment of reflexes, gait, coordination, and imaging results if mentioned.\n",
    "        3) For functional abilities, describe the patient's level of independence in activities of daily life and any changes from previous status that are noted.\n",
    "        4) For relevant medical history, list comorbidities and chronic conditions, especially ones that may affect cognitive or functional status. Please also describe current symptoms and any treatments received.\n",
    "         Please use precise clinical language suitable for a medical professional audience.\n",
    "        Here are the patient's clinical notes for all their hospital stays: {text}\"\"\"\n",
    "        #################################################################\n",
    "\n",
    "        json_data = {\n",
    "            \"id\": row['subject_id'],\n",
    "            \"request\": {\n",
    "                \"contents\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"parts\": [{\"text\": prompt}]\n",
    "                    }\n",
    "                ],\n",
    "                \"generationConfig\": {\"temperature\": 0.4, \"maxOutputTokens\": 2048},\n",
    "\n",
    "            }\n",
    "        }\n",
    "        jsonl_data += json.dumps(json_data) + '\\n'\n",
    "\n",
    "    # Upload the JSONL data to GCS\n",
    "    blob.upload_from_string(jsonl_data, content_type='application/jsonl')\n",
    "    print(f\"JSONL file uploaded to gs://{bucket_name}/{blob_name}\")\n",
    "\n",
    "    return f\"gs://{bucket_name}/{blob_name}\"\n",
    "\n",
    "### TO DO: Change bucket name ##############################\n",
    "\n",
    "BUCKET_NAME = 'project_summary_regex'\n",
    "input_uri = df_to_jsonl_gcs(df_regex1, BUCKET_NAME, 'gemini_batch_requests.jsonl')\n",
    "\n",
    "#################################################################\n",
    "\n",
    "output_uri = f\"gs://{BUCKET_NAME}/batch-prediction/\"\n",
    "\n",
    "# Submit a batch prediction job with Gemini model\n",
    "batch_prediction_job = BatchPredictionJob.submit(\n",
    "    source_model=\"gemini-1.5-flash-001\",\n",
    "    input_dataset=input_uri,\n",
    "    output_uri_prefix=output_uri,\n",
    ")\n",
    "\n",
    "# Check job status\n",
    "print(f\"Job resource name: {batch_prediction_job.resource_name}\")\n",
    "print(f\"Model resource name with the job: {batch_prediction_job.model_name}\")\n",
    "print(f\"Job state: {batch_prediction_job.state.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1561,
     "status": "ok",
     "timestamp": 1746150453098,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "gYwLCj0Z6K42",
    "outputId": "ac381551-15b2-4053-91b3-a59410c52ee0"
   },
   "outputs": [],
   "source": [
    "# Load the JSONL file into a DataFrame\n",
    "# once you've made your predictions, they should be\n",
    "# stored at your google cloud storage bucket specified by the path\n",
    "# and you should be able to download it from this path\n",
    "path = 'gs://project_summary_regex/batch-prediction/prediction-model-2025-05-01T17:52:06.906636Z'\n",
    "output_path = path + '/predictions.jsonl'\n",
    "\n",
    "summaries_df = pd.read_json(output_path, lines=True)\n",
    "summaries_df = summaries_df.join(pd.json_normalize(summaries_df[\"response\"], \"candidates\"))\n",
    "print(summaries_df.shape)\n",
    "\n",
    "# Note some inputs may not generate predictions due to SAFETY constraints\n",
    "summaries_df['summary'] = summaries_df['response'].apply(extract_text)\n",
    "summaries_df = summaries_df[summaries_df['summary'] != '']\n",
    "print(summaries_df.shape)\n",
    "\n",
    "summaries_df = summaries_df[['id', 'summary']]\n",
    "summaries_df.columns = ['subject_id', 'gemini_summary']\n",
    "summaries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "executionInfo": {
     "elapsed": 2441,
     "status": "ok",
     "timestamp": 1746150464852,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "K5YUlN_N6K0J",
    "outputId": "90d67a66-aa2f-4cd9-eaec-c312d77ae08c"
   },
   "outputs": [],
   "source": [
    "df_regex1['subject_id'] = df_regex1['subject_id'].astype(int)\n",
    "df_regex2 = pd.merge(df_regex1, summaries_df, on='subject_id', how='inner')\n",
    "print(df_regex2.shape)\n",
    "fn = '/content/drive/MyDrive/HSPH/Courses/MIT6.7930/AI Bias for AD/AI Bias AD/Gemini Prediction Model/13_regex_summaries.csv'\n",
    "df_regex2.to_csv(fn, index=False, header=True)\n",
    "df_regex2['case_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laFw_Ml7fc_e"
   },
   "source": [
    "## Gemini masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3648,
     "status": "ok",
     "timestamp": 1746150472477,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "FvPWNtna6Kxh",
    "outputId": "2068623f-50ad-4a38-eff9-91dd24bc875e"
   },
   "outputs": [],
   "source": [
    "fn = '/content/drive/MyDrive/HSPH/Courses/MIT6.7930/AI Bias for AD/AI Bias AD/Gemini Prediction Model/12_gemini_masked_concat.csv'\n",
    "df = pd.read_csv(fn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXRbbuH3f_pV"
   },
   "source": [
    "### First pass summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390235,
     "status": "ok",
     "timestamp": 1746148036822,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "AH4Gruepf_pW",
    "outputId": "f906508b-aec8-41a8-8840-922250820556"
   },
   "outputs": [],
   "source": [
    "def df_to_jsonl_gcs(df, bucket_name, blob_name):\n",
    "    \"\"\"Converts a DataFrame to JSONL and uploads to Google Cloud Storage.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame with a 'text' column.\n",
    "        bucket_name: Name of your Google Cloud Storage bucket.\n",
    "        blob_name: Desired name for the JSONL file on GCS.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a GCS client\n",
    "    storage_client = storage.Client(project=PROJECT_ID)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    if not bucket.exists():\n",
    "        bucket.create(location='US')\n",
    "        print(f'Bucket {bucket_name} created.')\n",
    "    else:\n",
    "        print(f'Bucket {bucket_name} already exists.')\n",
    "\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Write JSONL data to a string buffer\n",
    "    jsonl_data = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "        ### TO DO: Provide Gemini a prompt ##############################\n",
    "        # Edit the prompt to tell Gemini how to handle your input text\n",
    "        text = row['concatenated_notes']#[:50000]\n",
    "\n",
    "        prompt = f\"\"\"You are a neurologist tasked with providing observations and summaries of clinical notes. Each clinical note corresponds to one hospital admission for a patient. Based on the clinical notes provided, please comment on each of the domains listed below:\n",
    "        1) For cognitive status, describe memory, attention, language, and executive function findings. Please also describe any current sleep patterns and any notable changes in sleep patterns that are documented.\n",
    "        2) For neurological findings, describe the circumstances and results of any motor and sensory tests performed including assessment of reflexes, gait, coordination, and imaging results if mentioned.\n",
    "        3) For functional abilities, describe the patient's level of independence in activities of daily life and any changes from previous status that are noted.\n",
    "        4) For relevant medical history, list comorbidities and chronic conditions, especially ones that may affect cognitive or functional status. Please also describe current symptoms and any treatments received.\n",
    "         Please use precise clinical language suitable for a medical professional audience.\n",
    "        Here are the patient's clinical notes for their hospital stay: {text}\"\"\"\n",
    "        #################################################################\n",
    "\n",
    "        json_data = {\n",
    "            \"id\": row['id'],\n",
    "            \"request\": {\n",
    "                \"contents\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"parts\": [{\"text\": prompt}]\n",
    "                    }\n",
    "                ],\n",
    "                \"generationConfig\": {\"temperature\": 0.4, \"maxOutputTokens\": 2048},\n",
    "\n",
    "            }\n",
    "        }\n",
    "        jsonl_data += json.dumps(json_data) + '\\n'\n",
    "\n",
    "    # Upload the JSONL data to GCS\n",
    "    blob.upload_from_string(jsonl_data, content_type='application/jsonl')\n",
    "    print(f\"JSONL file uploaded to gs://{bucket_name}/{blob_name}\")\n",
    "\n",
    "    return f\"gs://{bucket_name}/{blob_name}\"\n",
    "\n",
    "### TO DO: Change bucket name ##############################\n",
    "\n",
    "BUCKET_NAME = 'project_summary_gemini'\n",
    "input_uri = df_to_jsonl_gcs(df, BUCKET_NAME, 'gemini_batch_requests.jsonl')\n",
    "\n",
    "#################################################################\n",
    "\n",
    "output_uri = f\"gs://{BUCKET_NAME}/batch-prediction/\"\n",
    "\n",
    "# Submit a batch prediction job with Gemini model\n",
    "batch_prediction_job = BatchPredictionJob.submit(\n",
    "    source_model=\"gemini-1.5-flash-001\",\n",
    "    input_dataset=input_uri,\n",
    "    output_uri_prefix=output_uri,\n",
    ")\n",
    "\n",
    "# Check job status\n",
    "print(f\"Job resource name: {batch_prediction_job.resource_name}\")\n",
    "print(f\"Model resource name with the job: {batch_prediction_job.model_name}\")\n",
    "print(f\"Job state: {batch_prediction_job.state.name}\")\n",
    "\n",
    "# Refresh the job until complete\n",
    "while not batch_prediction_job.has_ended:\n",
    "    time.sleep(5)\n",
    "    batch_prediction_job.refresh()\n",
    "\n",
    "# Check if the job succeeds\n",
    "if batch_prediction_job.has_succeeded:\n",
    "    print(\"Job succeeded!\")\n",
    "else:\n",
    "    print(f\"Job failed: {batch_prediction_job.error}\")\n",
    "\n",
    "# Check the location of the output\n",
    "print(f\"Job output location: {batch_prediction_job.output_location}\")\n",
    "\n",
    "# Example response:\n",
    "#  Job output location: gs://your-bucket/gen-ai-batch-prediction/prediction-model-year-month-day-hour:minute:second.12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5962,
     "status": "ok",
     "timestamp": 1746150492691,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "bMvAb-gYf_pW",
    "outputId": "0e592d1e-6f7f-411d-e205-82c0c9b40097"
   },
   "outputs": [],
   "source": [
    "# Load the JSONL file into a DataFrame\n",
    "# once you've made your predictions, they should be\n",
    "# stored at your google cloud storage bucket specified by the path\n",
    "# and you should be able to download it from this path\n",
    "path = 'gs://project_summary_gemini/batch-prediction/prediction-model-2025-05-02T01:00:51.356206Z'\n",
    "output_path = path + '/predictions.jsonl'\n",
    "\n",
    "summaries_df = pd.read_json(output_path, lines=True)\n",
    "summaries_df = summaries_df.join(pd.json_normalize(summaries_df[\"response\"], \"candidates\"))\n",
    "print(summaries_df.shape)\n",
    "\n",
    "# Note some inputs may not generate predictions due to SAFETY constraints\n",
    "summaries_df['summary'] = summaries_df['response'].apply(extract_text)\n",
    "summaries_df = summaries_df[summaries_df['summary'] != '']\n",
    "summaries_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1746150494925,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "wzTNicuzf_pW",
    "outputId": "d820e634-70b2-4b4d-8848-06fb34a969e7"
   },
   "outputs": [],
   "source": [
    "summaries_df = summaries_df[['id', 'summary']]\n",
    "summaries_df.columns = ['id_gemini', 'summary']\n",
    "summaries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1746150499150,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "GsecXDJwf_pX",
    "outputId": "68631cff-d0fb-4464-f3ca-d1a3b3a8f663"
   },
   "outputs": [],
   "source": [
    "df['id_gemini'] = df['id'].str.replace(r'[_-]', '', regex=True).astype(int)\n",
    "df_summs = pd.merge(df, summaries_df, on='id_gemini', how='inner')\n",
    "df_summs[['subject_id', 'hadm_id']] = df_summs['id'].str.split('_', n=1, expand=True)\n",
    "df_summs = df_summs.drop(['id', 'id_gemini', 'concatenated_notes'], axis=1)\n",
    "df_summs = df_summs.sort_values(by=['subject_id', 'admityear', 'admitmonth', 'admitday'])\n",
    "df_summs['hadm_id_long'] = 'Hospital Admittance ID: ' + df_summs['hadm_id']\n",
    "df_concat = df_summs.groupby('subject_id').apply(concatenate_notes).reset_index(name='concatenated_notes')\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1746150504013,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "SDwnZwUIf_pX",
    "outputId": "9814936e-8ffb-4cd3-a125-21758c9fedb1"
   },
   "outputs": [],
   "source": [
    "df_clean = df_summs.copy()\n",
    "df_clean = df_clean.drop(['admityear', 'admitmonth', 'admitday', 'summary', 'hadm_id', 'hadm_id_long'], axis=1)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "df_clean = df_clean[~df_clean.duplicated(subset='subject_id', keep='last')]\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1746150505694,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "UmZI4vaCf_pX",
    "outputId": "ff8f0074-fdc4-4146-c08f-1ad7a54cc6e4"
   },
   "outputs": [],
   "source": [
    "df_gemini1 = pd.merge(df_clean, df_concat, on='subject_id', how='inner')\n",
    "print(df_gemini1.shape)\n",
    "df_gemini1['case_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfbsRhrnf_pY"
   },
   "source": [
    "### Second pass summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1618,
     "status": "ok",
     "timestamp": 1746148324605,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "aXU2JgD-f_pY",
    "outputId": "bab3b0c4-10b8-4ec3-d9ed-886e6f5e3f7b"
   },
   "outputs": [],
   "source": [
    "def df_to_jsonl_gcs(df, bucket_name, blob_name):\n",
    "    \"\"\"Converts a DataFrame to JSONL and uploads to Google Cloud Storage.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame with a 'text' column.\n",
    "        bucket_name: Name of your Google Cloud Storage bucket.\n",
    "        blob_name: Desired name for the JSONL file on GCS.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a GCS client\n",
    "    storage_client = storage.Client(project=PROJECT_ID)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    if not bucket.exists():\n",
    "        bucket.create(location='US')\n",
    "        print(f'Bucket {bucket_name} created.')\n",
    "    else:\n",
    "        print(f'Bucket {bucket_name} already exists.')\n",
    "\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Write JSONL data to a string buffer\n",
    "    jsonl_data = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "        ### TO DO: Provide Gemini a prompt ##############################\n",
    "        # Edit the prompt to tell Gemini how to handle your input text\n",
    "        text = row['concatenated_notes']#[:50000]\n",
    "\n",
    "        prompt = f\"\"\"You are a neurologist tasked with providing a single summary of clinical notes. The clinical notes provided have been summarized for each hospital stay, but we want you to summarize them further so that we have a single summary for each patient. Based on the clinical notes provided, please summarise each of the domains listed below across the visits:\n",
    "        1) For cognitive status, describe memory, attention, language, and executive function findings. Please also describe any current sleep patterns and any notable changes in sleep patterns that are documented.\n",
    "        2) For neurological findings, describe the circumstances and results of any motor and sensory tests performed including assessment of reflexes, gait, coordination, and imaging results if mentioned.\n",
    "        3) For functional abilities, describe the patient's level of independence in activities of daily life and any changes from previous status that are noted.\n",
    "        4) For relevant medical history, list comorbidities and chronic conditions, especially ones that may affect cognitive or functional status. Please also describe current symptoms and any treatments received.\n",
    "         Please use precise clinical language suitable for a medical professional audience.\n",
    "        Here are the patient's clinical notes for all their hospital stays: {text}\"\"\"\n",
    "        #################################################################\n",
    "\n",
    "        json_data = {\n",
    "            \"id\": row['subject_id'],\n",
    "            \"request\": {\n",
    "                \"contents\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"parts\": [{\"text\": prompt}]\n",
    "                    }\n",
    "                ],\n",
    "                \"generationConfig\": {\"temperature\": 0.4, \"maxOutputTokens\": 2048},\n",
    "\n",
    "            }\n",
    "        }\n",
    "        jsonl_data += json.dumps(json_data) + '\\n'\n",
    "\n",
    "    # Upload the JSONL data to GCS\n",
    "    blob.upload_from_string(jsonl_data, content_type='application/jsonl')\n",
    "    print(f\"JSONL file uploaded to gs://{bucket_name}/{blob_name}\")\n",
    "\n",
    "    return f\"gs://{bucket_name}/{blob_name}\"\n",
    "\n",
    "### TO DO: Change bucket name ##############################\n",
    "\n",
    "BUCKET_NAME = 'project_summary_gemini'\n",
    "input_uri = df_to_jsonl_gcs(df_gemini1, BUCKET_NAME, 'gemini_batch_requests.jsonl')\n",
    "\n",
    "#################################################################\n",
    "\n",
    "output_uri = f\"gs://{BUCKET_NAME}/batch-prediction/\"\n",
    "\n",
    "# Submit a batch prediction job with Gemini model\n",
    "batch_prediction_job = BatchPredictionJob.submit(\n",
    "    source_model=\"gemini-1.5-flash-001\",\n",
    "    input_dataset=input_uri,\n",
    "    output_uri_prefix=output_uri,\n",
    ")\n",
    "\n",
    "# Check job status\n",
    "print(f\"Job resource name: {batch_prediction_job.resource_name}\")\n",
    "print(f\"Model resource name with the job: {batch_prediction_job.model_name}\")\n",
    "print(f\"Job state: {batch_prediction_job.state.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5267,
     "status": "ok",
     "timestamp": 1746148759555,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "SKbADOo9k3e2",
    "outputId": "2b22e5b0-f84c-4008-a280-f5a0bd850687"
   },
   "outputs": [],
   "source": [
    "# Refresh the job until complete\n",
    "while not batch_prediction_job.has_ended:\n",
    "    time.sleep(5)\n",
    "    batch_prediction_job.refresh()\n",
    "\n",
    "# Check if the job succeeds\n",
    "if batch_prediction_job.has_succeeded:\n",
    "    print(\"Job succeeded!\")\n",
    "else:\n",
    "    print(f\"Job failed: {batch_prediction_job.error}\")\n",
    "\n",
    "# Check the location of the output\n",
    "print(f\"Job output location: {batch_prediction_job.output_location}\")\n",
    "\n",
    "# Example response:\n",
    "#  Job output location: gs://your-bucket/gen-ai-batch-prediction/prediction-model-year-month-day-hour:minute:second.12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1344,
     "status": "ok",
     "timestamp": 1746150513696,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "BfeJ6Qg5f_pY",
    "outputId": "5b6575e1-28ba-43f3-9459-782c9b36afce"
   },
   "outputs": [],
   "source": [
    "# Load the JSONL file into a DataFrame\n",
    "# once you've made your predictions, they should be\n",
    "# stored at your google cloud storage bucket specified by the path\n",
    "# and you should be able to download it from this path\n",
    "path = 'gs://project_summary_gemini/batch-prediction/prediction-model-2025-05-02T01:12:04.668842Z'\n",
    "output_path = path + '/predictions.jsonl'\n",
    "\n",
    "summaries_df = pd.read_json(output_path, lines=True)\n",
    "summaries_df = summaries_df.join(pd.json_normalize(summaries_df[\"response\"], \"candidates\"))\n",
    "print(summaries_df.shape)\n",
    "\n",
    "# Note some inputs may not generate predictions due to SAFETY constraints\n",
    "summaries_df['summary'] = summaries_df['response'].apply(extract_text)\n",
    "summaries_df = summaries_df[summaries_df['summary'] != '']\n",
    "print(summaries_df.shape)\n",
    "\n",
    "summaries_df = summaries_df[['id', 'summary']]\n",
    "summaries_df.columns = ['subject_id', 'summary']\n",
    "summaries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "executionInfo": {
     "elapsed": 1725,
     "status": "ok",
     "timestamp": 1746150523732,
     "user": {
      "displayName": "Anya Greenberg",
      "userId": "05297501209462370660"
     },
     "user_tz": 240
    },
    "id": "uyWf25Idf_pY",
    "outputId": "48908d31-28d2-4a39-a671-5103f6343d62"
   },
   "outputs": [],
   "source": [
    "df_gemini1['subject_id'] = df_gemini1['subject_id'].astype(int)\n",
    "df_gemini2 = pd.merge(df_gemini1, summaries_df, on='subject_id', how='inner')\n",
    "print(df_gemini2.shape)\n",
    "fn = '/content/drive/MyDrive/HSPH/Courses/MIT6.7930/AI Bias for AD/AI Bias AD/Gemini Prediction Model/13_gemini_summaries.csv'\n",
    "df_gemini2.to_csv(fn, index=False, header=True)\n",
    "df_gemini2['case_status'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPRPDyelVfR9KDj0ljbmDtP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
