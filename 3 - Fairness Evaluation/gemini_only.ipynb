{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeA1NCY1BlMU",
        "outputId": "7c2e8bb6-a98a-4a5b-f130-a2acc7f2d505"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgl6wo2Og0ZD"
      },
      "source": [
        "# Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "n5yFaavxR0Vp",
        "outputId": "69642c0c-9dd2-467a-dafd-d9681b940830"
      },
      "outputs": [],
      "source": [
        "dir = '/content/drive/MyDrive/HSPH/Courses/MIT6.7930/AI Bias for AD/AI Bias AD/Gemini Prediction Model/summaries_predictions/'\n",
        "\n",
        "final_df=pd.read_csv(dir + \"15_gemini_predictions-gemini_summaries_tabular.csv\")\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-WEpx9aB66s",
        "outputId": "3d72b7dc-ec0e-48da-b219-3a3a7d119752"
      },
      "outputs": [],
      "source": [
        "likely = final_df[final_df['gemini_pred'] != 'POSSIBLE_AD'].copy()\n",
        "likely['pred'] = [0 if x == 'UNLIKELY_AD' else 1 for x in likely['gemini_pred']]\n",
        "print(likely['gemini_pred'].value_counts())\n",
        "print(likely['pred'].value_counts())\n",
        "true_pred = sum(likely['pred'] == likely['case_status'])\n",
        "acc = true_pred/len(likely)\n",
        "print('Accuracy: %s' % round(acc,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26EQ2qkcNrOy",
        "outputId": "096000df-4f51-42a3-f72e-0ff4a7a411c2"
      },
      "outputs": [],
      "source": [
        "possible = final_df[final_df['gemini_pred'] != 'LIKELY_AD'].copy()\n",
        "print(possible['gemini_pred'].value_counts())\n",
        "possible['pred'] = [0 if x == 'UNLIKELY_AD' else 1 for x in possible['gemini_pred']]\n",
        "print(possible['gemini_pred'].value_counts())\n",
        "print(possible['pred'].value_counts())\n",
        "true_pred = sum(possible['pred'] == possible['case_status'])\n",
        "acc = true_pred/len(possible)\n",
        "print('Accuracy: %s' % round(acc,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQrUTDnPbjy5"
      },
      "source": [
        "# Test Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wVOeyzJ6WYZ"
      },
      "source": [
        "⚖️ Why These Metrics?\n",
        "\n",
        "In a classification task (e.g., predicting case_status), fairness means the model's decisions should not unfairly disadvantage people from certain groups (like gender, race, age, etc.).\n",
        "\n",
        "To assess this, we compare how well or how consistently the model performs across different subgroups. Each of the three metrics measures a specific kind of fairness.\n",
        "\n",
        "🔹 1. Equal Opportunity (TPR)\n",
        "\n",
        "The True Positive Rate (TP / [TP + FN]) should be equal across groups.\n",
        "\n",
        "Why it matters:\n",
        "\n",
        "This ensures that qualified individuals (i.e., people who truly belong to the positive class) are equally likely to be correctly identified, no matter their demographic. It aims for equal performance for both positive and negative predictions across groups, ensuring that neither group benefits or suffers disproportionately from the model's decisions.\n",
        "\n",
        "Example: In healthcare, all patients who actually need treatment (true positives) should have an equal chance of being correctly identified — regardless of race or gender.\n",
        "\n",
        "Bias implication:\n",
        "\n",
        "If Group A has TPR = 0.9 and Group B has TPR = 0.6 → the model is less likely to help Group B, even if they qualify. That’s discriminatory.\n",
        "\n",
        "🔹 2. Predictive Parity (Precision)\n",
        "The Precision (TP / [TP + FP]) should be equal across groups.\n",
        "\n",
        "Why it matters:\n",
        "\n",
        "This ensures that those who are predicted to be positive actually are, at equal rates across groups.\n",
        "\n",
        "In practical terms, it means the model is equally trustworthy in its positive predictions for all groups.\n",
        "\n",
        "Bias implication:\n",
        "\n",
        "If Group A has 80% precision and Group B has 50% → Group B suffers more false alarms or unjustified interventions, which is unfair.\n",
        "\n",
        "🔹 3. Equalized Odds (TPR & FPR)\n",
        "\n",
        "Both TPR and FPR (False Positive Rate = FP / [FP + TN]) should be equal across groups.\n",
        "\n",
        "Why it matters:\n",
        "\n",
        "This is the most comprehensive fairness metric.\n",
        "\n",
        "It ensures the model:\n",
        "\n",
        "✅ correctly identifies positives at the same rate (Equal Opportunity)\n",
        "\n",
        "❌ doesn’t falsely accuse negatives at different rates (False alarms)\n",
        "\n",
        "Bias implication:\n",
        "\n",
        "If Group A has FPR = 0.1 and Group B has FPR = 0.3 → Group B receives more false accusations, which can be harmful or costly (e.g., wrongful arrests, misdiagnoses).\n",
        "\n",
        "🧠 Summary Table\n",
        "\n",
        "Metric\tMeasures\tPrevents Bias Where...\n",
        "\n",
        "Equal Opportunity\tTPR\tQualified individuals are denied more often in some groups\n",
        "\n",
        "Predictive Parity\tPrecision\tSome groups receive more incorrect positive predictions\n",
        "\n",
        "Equalized Odds\tTPR & FPR\tSome groups are both over- or under-predicted unfairly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRoxc-zuNaoE"
      },
      "source": [
        "#### Overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwIwS5-DEdj2",
        "outputId": "436a83eb-7e47-4a1c-c440-9c79f7456abb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Get ground truth and predictions\n",
        "y_true = likely['case_status']\n",
        "y_pred = likely['pred']\n",
        "\n",
        "# Compute confusion matrix\n",
        "try:\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "except ValueError:\n",
        "    # Handle edge cases where only one class is present\n",
        "    tn = fp = fn = tp = 0\n",
        "    for actual, pred in zip(y_true, y_pred):\n",
        "        if actual == 1 and pred == 1:\n",
        "            tp += 1\n",
        "        elif actual == 1 and pred == 0:\n",
        "            fn += 1\n",
        "        elif actual == 0 and pred == 1:\n",
        "            fp += 1\n",
        "        elif actual == 0 and pred == 0:\n",
        "            tn += 1\n",
        "\n",
        "# Compute fairness-related metrics\n",
        "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # Sensitivity / Equal Opportunity\n",
        "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0  # False Positive Rate / Equalized Odds\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0  # Precision / Predictive Parity\n",
        "sample_size = len(likely)\n",
        "\n",
        "# Print results\n",
        "print(\"📊 Overall Model Performance on Data\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"TPR:       {tpr:.4f}\")\n",
        "print(f\"FPR:       {fpr:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Sample Size:  {sample_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZr4HUeSCZTZ",
        "outputId": "cb15192a-4a13-42ff-cd18-44df8ec44407"
      },
      "outputs": [],
      "source": [
        "# Get ground truth and predictions\n",
        "y_true = possible['case_status']\n",
        "y_pred = possible['pred']\n",
        "\n",
        "# Compute confusion matrix\n",
        "try:\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "except ValueError:\n",
        "    # Handle edge cases where only one class is present\n",
        "    tn = fp = fn = tp = 0\n",
        "    for actual, pred in zip(y_true, y_pred):\n",
        "        if actual == 1 and pred == 1:\n",
        "            tp += 1\n",
        "        elif actual == 1 and pred == 0:\n",
        "            fn += 1\n",
        "        elif actual == 0 and pred == 1:\n",
        "            fp += 1\n",
        "        elif actual == 0 and pred == 0:\n",
        "            tn += 1\n",
        "\n",
        "# Compute fairness-related metrics\n",
        "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # Sensitivity / Equal Opportunity\n",
        "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0  # False Positive Rate / Equalized Odds\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0  # Precision / Predictive Parity\n",
        "sample_size = len(possible)\n",
        "\n",
        "# Print results\n",
        "print(\"📊 Overall Model Performance on Data\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"TPR:       {tpr:.4f}\")\n",
        "print(f\"FPR:       {fpr:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Sample Size:  {sample_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfVQ9J6gNzc9"
      },
      "source": [
        "# Bias Validation - Likely"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYzmJ8zrGPaA"
      },
      "source": [
        "## Sample performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onGydhKbN02K",
        "outputId": "1873a1af-fbc4-4ac2-ec2b-d832c47f6d82"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tabulate import tabulate\n",
        "\n",
        "# === Age binning ===\n",
        "def bin_age(df):\n",
        "    bin_edges = [0, 70, 80, 90, float('inf')]\n",
        "    labels = ['<70', '70-80', '80-90', '>90']\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    return df\n",
        "\n",
        "# === Bootstrap metrics: TPR, FPR, Precision only ===\n",
        "def bootstrap_metrics(y_true, y_pred, n_iterations=100):\n",
        "    stats = {'TPR': [], 'FPR': [], 'Precision': []}\n",
        "    for _ in range(n_iterations):\n",
        "        try:\n",
        "            sample = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred}).sample(frac=1.0, replace=True)\n",
        "            yt = sample['y_true']\n",
        "            yp = sample['y_pred']\n",
        "            tn, fp, fn, tp = confusion_matrix(yt, yp, labels=[0, 1]).ravel()\n",
        "            tpr = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
        "            fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
        "            stats['TPR'].append(tpr)\n",
        "            stats['FPR'].append(fpr)\n",
        "            stats['Precision'].append(precision)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return {\n",
        "        'TPR': (np.nanpercentile(stats['TPR'], 2.5), np.nanpercentile(stats['TPR'], 97.5)),\n",
        "        'FPR': (np.nanpercentile(stats['FPR'], 2.5), np.nanpercentile(stats['FPR'], 97.5)),\n",
        "        'Precision': (np.nanpercentile(stats['Precision'], 2.5), np.nanpercentile(stats['Precision'], 97.5)),\n",
        "    }\n",
        "\n",
        "# === Apply binning to age ===\n",
        "likely = bin_age(likely)\n",
        "\n",
        "# === Demographic groups ===\n",
        "demographic_groups = ['age_group', 'gender', 'insurance_group', 'language_group',\n",
        "                      'race_group1', 'race_group2', 'race_group3', 'race_group4']\n",
        "\n",
        "# === Run analysis for Train and Test ===\n",
        "data= likely\n",
        "records = []\n",
        "\n",
        "for group_col in demographic_groups:\n",
        "    if group_col not in data.columns:\n",
        "        continue\n",
        "\n",
        "    group_values = data[group_col].dropna().unique()\n",
        "\n",
        "    for value in group_values:\n",
        "        subset = data[data[group_col] == value]\n",
        "        if len(subset) < 10:\n",
        "            continue  # skip small groups\n",
        "\n",
        "        y_true = subset['case_status']\n",
        "        y_pred = subset['pred']\n",
        "        ci = bootstrap_metrics(y_true, y_pred)\n",
        "\n",
        "        records.append({\n",
        "            'Group': group_col,\n",
        "            'Subgroup': value,\n",
        "            'Equal Opportunity (TPR)': f\"{ci['TPR'][0]:.3f}–{ci['TPR'][1]:.3f}\",\n",
        "            'False Positive Rate (FPR)': f\"{ci['FPR'][0]:.3f}–{ci['FPR'][1]:.3f}\",\n",
        "            'Precision (Predictive Parity)': f\"{ci['Precision'][0]:.3f}–{ci['Precision'][1]:.3f}\",\n",
        "            'Sample Size': len(subset)\n",
        "        })\n",
        "\n",
        "df_metrics = pd.DataFrame(records)\n",
        "print(f\"\\n=== Fairness Metrics Per Subgroup ===\")\n",
        "print(tabulate(df_metrics, headers=\"keys\", tablefmt=\"fancy_grid\", showindex=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWE89rWhAgNe"
      },
      "source": [
        "## Check Equalized Opportunity Violations -  pairwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBQoHKpPCR4f"
      },
      "source": [
        "`proportions_ztest`: Compares proportions between two independent groups to see if they're different"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSvmpifpAfij",
        "outputId": "68439d12-fd2e-4e17-80cf-29d79b281825"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "def compute_tpr_components(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "    return tp, fn  # TPR = TP / (TP + FN)\n",
        "\n",
        "def test_tpr_difference(df, group_col, y_true_col='case_status', y_pred_col='pred'):\n",
        "    values = df[group_col].dropna().unique()\n",
        "    results = []\n",
        "\n",
        "    for i in range(len(values)):\n",
        "        for j in range(i+1, len(values)):\n",
        "            g1, g2 = values[i], values[j]\n",
        "            df1 = df[df[group_col] == g1]\n",
        "            df2 = df[df[group_col] == g2]\n",
        "\n",
        "            if len(df1) < 10 or len(df2) < 10:\n",
        "                continue  # skip small groups\n",
        "\n",
        "            try:\n",
        "                tp1, fn1 = compute_tpr_components(df1[y_true_col], df1[y_pred_col])\n",
        "                tp2, fn2 = compute_tpr_components(df2[y_true_col], df2[y_pred_col])\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            count = [tp1, tp2]\n",
        "            nobs = [tp1 + fn1, tp2 + fn2]\n",
        "\n",
        "            if min(nobs) == 0:\n",
        "                continue  # skip invalid\n",
        "\n",
        "            stat, pval = proportions_ztest(count, nobs)\n",
        "            if pval < 0.05:\n",
        "                results.append({\n",
        "                    'Demographic': group_col,\n",
        "                    'Group 1': g1,\n",
        "                    'Group 2': g2,\n",
        "                    'TPR 1': f\"{tp1 / nobs[0]:.3f}\",\n",
        "                    'TPR 2': f\"{tp2 / nobs[1]:.3f}\",\n",
        "                    'p-value': round(pval, 4)\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# === Run for each demographic column ===\n",
        "demographic_groups = ['age_group', 'gender', 'insurance_group', 'language_group',\n",
        "                      'race_group1', 'race_group2', 'race_group3', 'race_group4']\n",
        "\n",
        "for group_col in demographic_groups:\n",
        "    print(f\"\\n=== TPR differences in {group_col} ===\")\n",
        "    df_tpr_diff = test_tpr_difference(likely, group_col)\n",
        "    if df_tpr_diff.empty:\n",
        "        print(\"No significant TPR differences.\")\n",
        "    else:\n",
        "        print(df_tpr_diff)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3itOcVTB54A"
      },
      "source": [
        "## Check Equalized Opportunity Violations - group\n",
        "\n",
        "`chi2_contingency`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOX-3DkLB_5p",
        "outputId": "ec6a846f-0eab-464b-fdd8-0fc0f9e3521a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.stats import chi2_contingency\n",
        "import pandas as pd\n",
        "\n",
        "def chi2_test_tpr(df, group_col, y_true_col='case_status', y_pred_col='pred'):\n",
        "    table = []\n",
        "    labels = []\n",
        "\n",
        "    for val in df[group_col].dropna().unique():\n",
        "        subset = df[df[group_col] == val]\n",
        "        if len(subset) < 10:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tn, fp, fn, tp = confusion_matrix(subset[y_true_col], subset[y_pred_col], labels=[0,1]).ravel()\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        table.append([tp, fn])  # TPR = TP / (TP + FN)\n",
        "        labels.append(val)\n",
        "\n",
        "    if len(table) < 2:\n",
        "        return None, None, None\n",
        "\n",
        "    stat, pval, _, expected = chi2_contingency(table)\n",
        "\n",
        "    return pd.DataFrame(table, index=labels, columns=['TP', 'FN']), pval, stat\n",
        "\n",
        "# Example usage:\n",
        "for group in demographic_groups:\n",
        "    print(f\"\\n=== TPR difference test across {group} ===\")\n",
        "    contingency_df, pval, stat = chi2_test_tpr(likely, group)\n",
        "\n",
        "    if contingency_df is None:\n",
        "        print(\"Not enough valid groups.\")\n",
        "    else:\n",
        "        print(contingency_df)\n",
        "        print(f\"Chi-squared p-value: {pval:.4f}\")\n",
        "        if pval < 0.05:\n",
        "            print(\"✅ Significant TPR difference across subgroups.\")\n",
        "        else:\n",
        "            print(\"❌ No significant TPR difference across subgroups.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmnXQjiwB2x0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvcJBdkUBSSY"
      },
      "source": [
        "## Check Predictive Parity Violations -  Pairwise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIQiW_YuCrm8",
        "outputId": "4f0a33e6-d210-4258-f45a-fd3eb517682b"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "def compute_precision_components(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "    return tp, fp  # Precision = TP / (TP + FP)\n",
        "\n",
        "def test_precision_difference(df, group_col, y_true_col='case_status', y_pred_col='pred'):\n",
        "    values = df[group_col].dropna().unique()\n",
        "    results = []\n",
        "\n",
        "    for i in range(len(values)):\n",
        "        for j in range(i+1, len(values)):\n",
        "            g1, g2 = values[i], values[j]\n",
        "            df1 = df[df[group_col] == g1]\n",
        "            df2 = df[df[group_col] == g2]\n",
        "\n",
        "            if len(df1) < 10 or len(df2) < 10:\n",
        "                continue  # skip small groups\n",
        "\n",
        "            try:\n",
        "                tp1, fp1 = compute_precision_components(df1[y_true_col], df1[y_pred_col])\n",
        "                tp2, fp2 = compute_precision_components(df2[y_true_col], df2[y_pred_col])\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            count = [tp1, tp2]\n",
        "            nobs = [tp1 + fp1, tp2 + fp2]\n",
        "\n",
        "            if min(nobs) == 0:\n",
        "                continue  # skip invalid\n",
        "\n",
        "            stat, pval = proportions_ztest(count, nobs)\n",
        "            if pval < 0.05:\n",
        "                results.append({\n",
        "                    'Demographic': group_col,\n",
        "                    'Group 1': g1,\n",
        "                    'Group 2': g2,\n",
        "                    'Precision 1': f\"{tp1 / nobs[0]:.3f}\",\n",
        "                    'Precision 2': f\"{tp2 / nobs[1]:.3f}\",\n",
        "                    'p-value': round(pval, 4)\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "for group_col in demographic_groups:\n",
        "    print(f\"\\n=== Precision differences in {group_col} ===\")\n",
        "    df_precision_diff = test_precision_difference(likely, group_col)\n",
        "    if df_precision_diff.empty:\n",
        "        print(\"No significant Precision differences.\")\n",
        "    else:\n",
        "        print(df_precision_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g30BJa9bCqBi"
      },
      "source": [
        "## Check Predictive Parity Violations -  group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo1kf6iMCutz",
        "outputId": "cef50a59-2b80-4396-dfcc-0d0dcb566e3c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.stats import chi2_contingency\n",
        "import pandas as pd\n",
        "\n",
        "def chi2_test_precision(df, group_col, y_true_col='case_status', y_pred_col='pred'):\n",
        "    table = []\n",
        "    labels = []\n",
        "\n",
        "    for val in df[group_col].dropna().unique():\n",
        "        subset = df[df[group_col] == val]\n",
        "        if len(subset) < 10:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tn, fp, fn, tp = confusion_matrix(subset[y_true_col], subset[y_pred_col], labels=[0, 1]).ravel()\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        table.append([tp, fp])  # Precision = TP / (TP + FP)\n",
        "        labels.append(val)\n",
        "\n",
        "    if len(table) < 2:\n",
        "        return None, None, None\n",
        "\n",
        "    stat, pval, _, expected = chi2_contingency(table)\n",
        "\n",
        "    return pd.DataFrame(table, index=labels, columns=['TP', 'FP']), pval, stat\n",
        "\n",
        "for group in demographic_groups:\n",
        "    print(f\"\\n=== Precision difference test across {group} ===\")\n",
        "    contingency_df, pval, stat = chi2_test_precision(likely, group)\n",
        "\n",
        "    if contingency_df is None:\n",
        "        print(\"Not enough valid groups.\")\n",
        "    else:\n",
        "        print(contingency_df)\n",
        "        print(f\"Chi-squared p-value: {pval:.4f}\")\n",
        "        if pval < 0.05:\n",
        "            print(\"✅ Significant Precision difference across subgroups.\")\n",
        "        else:\n",
        "            print(\"❌ No significant Precision difference across subgroups.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KZO8RxDEptc"
      },
      "source": [
        "## Check Equalized odds Violations -  pairwise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TX1azuU9ti5",
        "outputId": "b649461c-40ef-406a-f674-05b1bbc3cf2e"
      },
      "outputs": [],
      "source": [
        "# pip install fairlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwymxBvNEqE0",
        "outputId": "2401b7bd-8249-4c43-9326-5801c46b5b15"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fairlearn.metrics import equalized_odds_difference\n",
        "from itertools import combinations\n",
        "from tabulate import tabulate\n",
        "\n",
        "# === Age binning ===\n",
        "def bin_age(df):\n",
        "    bin_edges = [0, 70, 80, 90, float('inf')]\n",
        "    labels = ['<70', '70-80', '80-90', '>90']\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    return df\n",
        "\n",
        "# === Bootstrap EOD for two subgroups only ===\n",
        "def bootstrap_pairwise_eod(y_true, y_pred, sensitive_features, n_iterations=100):\n",
        "    eods = []\n",
        "    data = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'sensitive': sensitive_features})\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        sample = data.sample(frac=1.0, replace=True)\n",
        "        try:\n",
        "            eod = equalized_odds_difference(sample['y_true'], sample['y_pred'], sensitive_features=sample['sensitive'])\n",
        "            eods.append(eod)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if len(eods) == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    return (\n",
        "        np.nanpercentile(eods, 2.5),\n",
        "        np.nanpercentile(eods, 97.5)\n",
        "    )\n",
        "\n",
        "# === Apply age binning ===\n",
        "likely = bin_age(likely)\n",
        "\n",
        "# === Filter to test set only ===\n",
        "test_data = likely\n",
        "\n",
        "# === Demographic groups ===\n",
        "demographic_groups = ['age_group', 'gender', 'insurance_group', 'language_group',\n",
        "                      'race_group1', 'race_group2', 'race_group3', 'race_group4']\n",
        "\n",
        "# === Pairwise EOD comparisons on test set ===\n",
        "records = []\n",
        "\n",
        "for group in demographic_groups:\n",
        "    if group not in test_data.columns:\n",
        "        continue\n",
        "\n",
        "    group_values = test_data[group].dropna().unique()\n",
        "\n",
        "    for g1, g2 in combinations(group_values, 2):\n",
        "        pair_df = test_data[test_data[group].isin([g1, g2])]\n",
        "        if len(pair_df) < 20:\n",
        "            continue  # skip small pair\n",
        "\n",
        "        y_true = pair_df['case_status']\n",
        "        y_pred = pair_df['pred']\n",
        "        sensitive_pair = pair_df[group]\n",
        "\n",
        "        # Compute bootstrapped EOD CI\n",
        "        eod_low, eod_high = bootstrap_pairwise_eod(y_true, y_pred, sensitive_pair)\n",
        "\n",
        "        records.append({\n",
        "            'Group': group,\n",
        "            'Subgroup 1': g1,\n",
        "            'Subgroup 2': g2,\n",
        "            'EOD (95% CI)': f\"{eod_low:.3f}–{eod_high:.3f}\",\n",
        "            'Sample Size': len(pair_df),\n",
        "            'Flag (EOD > 0.1)': '⚠️' if eod_low > 0.1 else ''\n",
        "        })\n",
        "\n",
        "# === Print nicely ===\n",
        "df_pairwise = pd.DataFrame(records)\n",
        "print(\"\\n=== Pairwise Equalized Odds Report ===\")\n",
        "print(tabulate(df_pairwise, headers=\"keys\", tablefmt=\"fancy_grid\", showindex=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2q1LLYF--Xj"
      },
      "source": [
        "## Check Equalized odds Violations -  group\n",
        "\n",
        "https://fairlearn.org/v0.7.0/api_reference/fairlearn.metrics.html\n",
        "\n",
        "fairlearn.metrics.equalized_odds_difference(y_true, y_pred, *, sensitive_features, method='between_groups', sample_weight=None)[source]\n",
        "Calculate the equalized odds difference.\n",
        "\n",
        "The greater of two metrics: true_positive_rate_difference and false_positive_rate_difference. The former is the difference between the largest and smallest of\n",
        ", across all values\n",
        " of the sensitive feature(s). The latter is defined similarly, but for\n",
        ". The equalized odds difference of 0 means that all groups have the same true positive, true negative, false positive, and false negative rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKhHpVIs5tiq",
        "outputId": "a3ea0ae7-6e78-4871-f36f-2f3e336353de"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fairlearn.metrics import equalized_odds_difference\n",
        "\n",
        "# === Age binning ===\n",
        "def bin_age(df):\n",
        "    bin_edges = [0, 70, 80, 90, float('inf')]\n",
        "    labels = ['<70', '70-80', '80-90', '>90']\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    return df\n",
        "\n",
        "# === Bootstrap EOD CI only ===\n",
        "def bootstrap_eod(y_true, y_pred, sensitive_features, n_iterations=100):\n",
        "    eods = []\n",
        "    data = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'sensitive': sensitive_features})\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        sample = data.sample(frac=1.0, replace=True)\n",
        "        try:\n",
        "            eod = equalized_odds_difference(sample['y_true'], sample['y_pred'], sensitive_features=sample['sensitive'])\n",
        "            eods.append(eod)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if len(eods) == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    return (\n",
        "        np.nanpercentile(eods, 2.5),\n",
        "        np.nanpercentile(eods, 97.5)\n",
        "    )\n",
        "\n",
        "# === Apply age binning ===\n",
        "likely = bin_age(likely)\n",
        "\n",
        "# === Demographic groups ===\n",
        "demographic_groups = ['age_group', 'gender', 'insurance_group', 'language_group',\n",
        "                      'race_group1', 'race_group2', 'race_group3', 'race_group4']\n",
        "\n",
        "# === Run analysis for Train and Test ===\n",
        "data=likely\n",
        "records = []\n",
        "\n",
        "for group in demographic_groups:\n",
        "    if group not in data.columns:\n",
        "        continue\n",
        "\n",
        "    sensitive = data[group]\n",
        "    valid = sensitive.notna()\n",
        "    y_true = data.loc[valid, 'case_status']\n",
        "    y_pred = data.loc[valid, 'pred']\n",
        "    sensitive_group = sensitive[valid]\n",
        "\n",
        "    if len(sensitive_group.unique()) < 2:\n",
        "        continue  # skip if only one group value\n",
        "\n",
        "    # Compute EOD CI\n",
        "    eod_low, eod_high = bootstrap_eod(y_true, y_pred, sensitive_group)\n",
        "\n",
        "    records.append({\n",
        "        'Group': group,\n",
        "        'Equalized Odds Difference (95% CI)': f\"{eod_low:.3f}–{eod_high:.3f}\",\n",
        "        'Sample Size': len(sensitive_group),\n",
        "        'Flag (EOD > 0.1)': '⚠️' if eod_low > 0.1 else ''\n",
        "    })\n",
        "\n",
        "# Create and display results\n",
        "df_metrics = pd.DataFrame(records)\n",
        "df_metrics.set_index('Group', inplace=True)\n",
        "\n",
        "print(f\"\\n=== Equalized Odds Report ===\")\n",
        "print(df_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWvAb3eZGPoE"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEBKvkcMGSX0"
      },
      "source": [
        "# Bias Validation - Possible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e5WKqbWGSX2"
      },
      "source": [
        "## Sample performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxZULAQCGSX3",
        "outputId": "63d3f425-a339-4647-972b-bd31f4c39c25"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tabulate import tabulate\n",
        "\n",
        "# === Age binning ===\n",
        "def bin_age(df):\n",
        "    bin_edges = [0, 70, 80, 90, float('inf')]\n",
        "    labels = ['<70', '70-80', '80-90', '>90']\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    return df\n",
        "\n",
        "# === Bootstrap metrics: TPR, FPR, Precision only ===\n",
        "def bootstrap_metrics(y_true, y_pred, n_iterations=100):\n",
        "    stats = {'TPR': [], 'FPR': [], 'Precision': []}\n",
        "    for _ in range(n_iterations):\n",
        "        try:\n",
        "            sample = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred}).sample(frac=1.0, replace=True)\n",
        "            yt = sample['y_true']\n",
        "            yp = sample['y_pred']\n",
        "            tn, fp, fn, tp = confusion_matrix(yt, yp, labels=[0, 1]).ravel()\n",
        "            tpr = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
        "            fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
        "            stats['TPR'].append(tpr)\n",
        "            stats['FPR'].append(fpr)\n",
        "            stats['Precision'].append(precision)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return {\n",
        "        'TPR': (np.nanpercentile(stats['TPR'], 2.5), np.nanpercentile(stats['TPR'], 97.5)),\n",
        "        'FPR': (np.nanpercentile(stats['FPR'], 2.5), np.nanpercentile(stats['FPR'], 97.5)),\n",
        "        'Precision': (np.nanpercentile(stats['Precision'], 2.5), np.nanpercentile(stats['Precision'], 97.5)),\n",
        "    }\n",
        "\n",
        "# === Apply binning to age ===\n",
        "possible = bin_age(possible)\n",
        "\n",
        "# === Demographic groups ===\n",
        "demographic_groups = ['age_group', 'gender', 'insurance_group', 'language_group',\n",
        "                      'race_group1', 'race_group2', 'race_group3', 'race_group4']\n",
        "\n",
        "# === Run analysis for Train and Test ===\n",
        "data= possible\n",
        "records = []\n",
        "\n",
        "for group_col in demographic_groups:\n",
        "    if group_col not in data.columns:\n",
        "        continue\n",
        "\n",
        "    group_values = data[group_col].dropna().unique()\n",
        "\n",
        "    for value in group_values:\n",
        "        subset = data[data[group_col] == value]\n",
        "        if len(subset) < 10:\n",
        "            continue  # skip small groups\n",
        "\n",
        "        y_true = subset['case_status']\n",
        "        y_pred = subset['pred']\n",
        "        ci = bootstrap_metrics(y_true, y_pred)\n",
        "\n",
        "        records.append({\n",
        "            'Group': group_col,\n",
        "            'Subgroup': value,\n",
        "            'Equal Opportunity (TPR)': f\"{ci['TPR'][0]:.3f}–{ci['TPR'][1]:.3f}\",\n",
        "            'False Positive Rate (FPR)': f\"{ci['FPR'][0]:.3f}–{ci['FPR'][1]:.3f}\",\n",
        "            'Precision (Predictive Parity)': f\"{ci['Precision'][0]:.3f}–{ci['Precision'][1]:.3f}\",\n",
        "            'Sample Size': len(subset)\n",
        "        })\n",
        "\n",
        "df_metrics = pd.DataFrame(records)\n",
        "print(f\"\\n=== Fairness Metrics Per Subgroup ===\")\n",
        "print(tabulate(df_metrics, headers=\"keys\", tablefmt=\"fancy_grid\", showindex=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOe2sJrUGSX5"
      },
      "source": [
        "## Check Equalized Opportunity Violations -  pairwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSOBGKjWGSX5"
      },
      "source": [
        "`proportions_ztest`: Compares proportions between two independent groups to see if they're different"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBruZdYQGSX6",
        "outputId": "32723a68-989d-438b-f7ca-8c724c9ce5e9"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "def compute_tpr_components(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "    return tp, fn  # TPR = TP / (TP + FN)\n",
        "\n",
        "def test_tpr_difference(df, group_col, y_true_col='case_status', y_pred_col='pred'):\n",
        "    values = df[group_col].dropna().unique()\n",
        "    results = []\n",
        "\n",
        "    for i in range(len(values)):\n",
        "        for j in range(i+1, len(values)):\n",
        "            g1, g2 = values[i], values[j]\n",
        "            df1 = df[df[group_col] == g1]\n",
        "            df2 = df[df[group_col] == g2]\n",
        "\n",
        "            if len(df1) < 10 or len(df2) < 10:\n",
        "                continue  # skip small groups\n",
        "\n",
        "            try:\n",
        "                tp1, fn1 = compute_tpr_components(df1[y_true_col], df1[y_pred_col])\n",
        "                tp2, fn2 = compute_tpr_components(df2[y_true_col], df2[y_pred_col])\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            count = [tp1, tp2]\n",
        "            nobs = [tp1 + fn1, tp2 + fn2]\n",
        "\n",
        "            if min(nobs) == 0:\n",
        "                continue  # skip invalid\n",
        "\n",
        "            stat, pval = proportions_ztest(count, nobs)\n",
        "            if pval < 0.05:\n",
        "                results.append({\n",
        "                    'Demographic': group_col,\n",
        "                    'Group 1': g1,\n",
        "                    'Group 2': g2,\n",
        "                    'TPR 1': f\"{tp1 / nobs[0]:.3f}\",\n",
        "                    'TPR 2': f\"{tp2 / nobs[1]:.3f}\",\n",
        "                    'p-value': round(pval, 4)\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# === Run for each demographic column ===\n",
        "demographic_groups = ['age_group', 'gender', 'insurance_group', 'language_group',\n",
        "                      'race_group1', 'race_group2', 'race_group3', 'race_group4']\n",
        "\n",
        "for group_col in demographic_groups:\n",
        "    print(f\"\\n=== TPR differences in {group_col} ===\")\n",
        "    df_tpr_diff = test_tpr_difference(possible, group_col)\n",
        "    if df_tpr_diff.empty:\n",
        "        print(\"No significant TPR differences.\")\n",
        "    else:\n",
        "        print(df_tpr_diff)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DirOnZakGSX7"
      },
      "source": [
        "## Check Equalized Opportunity Violations - group\n",
        "\n",
        "`chi2_contingency`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtFXZvOjGSX8",
        "outputId": "339af1ea-4389-4f71-f151-086a0601a5d4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.stats import chi2_contingency\n",
        "import pandas as pd\n",
        "\n",
        "def chi2_test_tpr(df, group_col, y_true_col='case_status', y_pred_col='pred'):\n",
        "    table = []\n",
        "    labels = []\n",
        "\n",
        "    for val in df[group_col].dropna().unique():\n",
        "        subset = df[df[group_col] == val]\n",
        "        if len(subset) < 10:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tn, fp, fn, tp = confusion_matrix(subset[y_true_col], subset[y_pred_col], labels=[0,1]).ravel()\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        table.append([tp, fn])  # TPR = TP / (TP + FN)\n",
        "        labels.append(val)\n",
        "\n",
        "    if len(table) < 2:\n",
        "        return None, None, None\n",
        "\n",
        "    stat, pval, _, expected = chi2_contingency(table)\n",
        "\n",
        "    return pd.DataFrame(table, index=labels, columns=['TP', 'FN']), pval, stat\n",
        "\n",
        "# Example usage:\n",
        "for group in demographic_groups:\n",
        "    print(f\"\\n=== TPR difference test across {group} ===\")\n",
        "    contingency_df, pval, stat = chi2_test_tpr(likely, group)\n",
        "\n",
        "    if contingency_df is None:\n",
        "        print(\"Not enough valid groups.\")\n",
        "    else:\n",
        "        print(contingency_df)\n",
        "        print(f\"Chi-squared p-value: {pval:.4f}\")\n",
        "        if pval < 0.05:\n",
        "            print(\"✅ Significant TPR difference across subgroups.\")\n",
        "        else:\n",
        "            print(\"❌ No significant TPR difference across subgroups.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHPvQj0dGSX8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT4knFGzGSX8"
      },
      "source": [
        "## Check Predictive Parity Violations -  Pairwise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aRQqsuMGSX9",
        "outputId": "caf45fea-b969-4046-bd9a-126f9b4e1eb2"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "def compute_precision_components(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "    return tp, fp  # Precision = TP / (TP + FP)\n",
        "\n",
        "def test_precision_difference(df, group_col, y_true_col='case_status', y_pred_col='pred'):\n",
        "    values = df[group_col].dropna().unique()\n",
        "    results = []\n",
        "\n",
        "    for i in range(len(values)):\n",
        "        for j in range(i+1, len(values)):\n",
        "            g1, g2 = values[i], values[j]\n",
        "            df1 = df[df[group_col] == g1]\n",
        "            df2 = df[df[group_col] == g2]\n",
        "\n",
        "            if len(df1) < 10 or len(df2) < 10:\n",
        "                continue  # skip small groups\n",
        "\n",
        "            try:\n",
        "                tp1, fp1 = compute_precision_components(df1[y_true_col], df1[y_pred_col])\n",
        "                tp2, fp2 = compute_precision_components(df2[y_true_col], df2[y_pred_col])\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            count = [tp1, tp2]\n",
        "            nobs = [tp1 + fp1, tp2 + fp2]\n",
        "\n",
        "            if min(nobs) == 0:\n",
        "                continue  # skip invalid\n",
        "\n",
        "            stat, pval = proportions_ztest(count, nobs)\n",
        "            if pval < 0.05:\n",
        "                results.append({\n",
        "                    'Demographic': group_col,\n",
        "                    'Group 1': g1,\n",
        "                    'Group 2': g2,\n",
        "                    'Precision 1': f\"{tp1 / nobs[0]:.3f}\",\n",
        "                    'Precision 2': f\"{tp2 / nobs[1]:.3f}\",\n",
        "                    'p-value': round(pval, 4)\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "for group_col in demographic_groups:\n",
        "    print(f\"\\n=== Precision differences in {group_col} ===\")\n",
        "    df_precision_diff = test_precision_difference(possible, group_col)\n",
        "    if df_precision_diff.empty:\n",
        "        print(\"No significant Precision differences.\")\n",
        "    else:\n",
        "        print(df_precision_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIMQPFsaGSX9"
      },
      "source": [
        "## Check Predictive Parity Violations -  group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqqzpuI3GSX-",
        "outputId": "51199416-0e21-4f7d-b1f2-a3c808dd9d53"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.stats import chi2_contingency\n",
        "import pandas as pd\n",
        "\n",
        "def chi2_test_precision(df, group_col, y_true_col='case_status', y_pred_col='pred'):\n",
        "    table = []\n",
        "    labels = []\n",
        "\n",
        "    for val in df[group_col].dropna().unique():\n",
        "        subset = df[df[group_col] == val]\n",
        "        if len(subset) < 10:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tn, fp, fn, tp = confusion_matrix(subset[y_true_col], subset[y_pred_col], labels=[0, 1]).ravel()\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        table.append([tp, fp])  # Precision = TP / (TP + FP)\n",
        "        labels.append(val)\n",
        "\n",
        "    if len(table) < 2:\n",
        "        return None, None, None\n",
        "\n",
        "    stat, pval, _, expected = chi2_contingency(table)\n",
        "\n",
        "    return pd.DataFrame(table, index=labels, columns=['TP', 'FP']), pval, stat\n",
        "\n",
        "for group in demographic_groups:\n",
        "    print(f\"\\n=== Precision difference test across {group} ===\")\n",
        "    contingency_df, pval, stat = chi2_test_precision(possible, group)\n",
        "\n",
        "    if contingency_df is None:\n",
        "        print(\"Not enough valid groups.\")\n",
        "    else:\n",
        "        print(contingency_df)\n",
        "        print(f\"Chi-squared p-value: {pval:.4f}\")\n",
        "        if pval < 0.05:\n",
        "            print(\"✅ Significant Precision difference across subgroups.\")\n",
        "        else:\n",
        "            print(\"❌ No significant Precision difference across subgroups.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJjT-fRHGSX-"
      },
      "source": [
        "## Check Equalized odds Violations -  pairwise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5BOym0CGSX_",
        "outputId": "af347239-ee39-4bc6-e740-e6cb65eac865"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fairlearn.metrics import equalized_odds_difference\n",
        "from itertools import combinations\n",
        "from tabulate import tabulate\n",
        "\n",
        "# === Age binning ===\n",
        "def bin_age(df):\n",
        "    bin_edges = [0, 70, 80, 90, float('inf')]\n",
        "    labels = ['<70', '70-80', '80-90', '>90']\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    return df\n",
        "\n",
        "# === Bootstrap EOD for two subgroups only ===\n",
        "def bootstrap_pairwise_eod(y_true, y_pred, sensitive_features, n_iterations=100):\n",
        "    eods = []\n",
        "    data = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'sensitive': sensitive_features})\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        sample = data.sample(frac=1.0, replace=True)\n",
        "        try:\n",
        "            eod = equalized_odds_difference(sample['y_true'], sample['y_pred'], sensitive_features=sample['sensitive'])\n",
        "            eods.append(eod)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if len(eods) == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    return (\n",
        "        np.nanpercentile(eods, 2.5),\n",
        "        np.nanpercentile(eods, 97.5)\n",
        "    )\n",
        "\n",
        "# === Apply age binning ===\n",
        "possible = bin_age(possible)\n",
        "\n",
        "# === Filter to test set only ===\n",
        "test_data = possible\n",
        "\n",
        "# === Demographic groups ===\n",
        "demographic_groups = ['age_group', 'gender', 'insurance_group', 'language_group',\n",
        "                      'race_group1', 'race_group2', 'race_group3', 'race_group4']\n",
        "\n",
        "# === Pairwise EOD comparisons on test set ===\n",
        "records = []\n",
        "\n",
        "for group in demographic_groups:\n",
        "    if group not in test_data.columns:\n",
        "        continue\n",
        "\n",
        "    group_values = test_data[group].dropna().unique()\n",
        "\n",
        "    for g1, g2 in combinations(group_values, 2):\n",
        "        pair_df = test_data[test_data[group].isin([g1, g2])]\n",
        "        if len(pair_df) < 20:\n",
        "            continue  # skip small pair\n",
        "\n",
        "        y_true = pair_df['case_status']\n",
        "        y_pred = pair_df['pred']\n",
        "        sensitive_pair = pair_df[group]\n",
        "\n",
        "        # Compute bootstrapped EOD CI\n",
        "        eod_low, eod_high = bootstrap_pairwise_eod(y_true, y_pred, sensitive_pair)\n",
        "\n",
        "        records.append({\n",
        "            'Group': group,\n",
        "            'Subgroup 1': g1,\n",
        "            'Subgroup 2': g2,\n",
        "            'EOD (95% CI)': f\"{eod_low:.3f}–{eod_high:.3f}\",\n",
        "            'Sample Size': len(pair_df),\n",
        "            'Flag (EOD > 0.1)': '⚠️' if eod_low > 0.1 else ''\n",
        "        })\n",
        "\n",
        "# === Print nicely ===\n",
        "df_pairwise = pd.DataFrame(records)\n",
        "print(\"\\n=== Pairwise Equalized Odds Report ===\")\n",
        "print(tabulate(df_pairwise, headers=\"keys\", tablefmt=\"fancy_grid\", showindex=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjUeLBz7GSX_"
      },
      "source": [
        "## Check Equalized odds Violations -  group\n",
        "\n",
        "https://fairlearn.org/v0.7.0/api_reference/fairlearn.metrics.html\n",
        "\n",
        "fairlearn.metrics.equalized_odds_difference(y_true, y_pred, *, sensitive_features, method='between_groups', sample_weight=None)[source]\n",
        "Calculate the equalized odds difference.\n",
        "\n",
        "The greater of two metrics: true_positive_rate_difference and false_positive_rate_difference. The former is the difference between the largest and smallest of\n",
        ", across all values\n",
        " of the sensitive feature(s). The latter is defined similarly, but for\n",
        ". The equalized odds difference of 0 means that all groups have the same true positive, true negative, false positive, and false negative rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6md_eG9GSYB",
        "outputId": "01443546-cecb-4210-8faa-68a2d16f241e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fairlearn.metrics import equalized_odds_difference\n",
        "\n",
        "# === Age binning ===\n",
        "def bin_age(df):\n",
        "    bin_edges = [0, 70, 80, 90, float('inf')]\n",
        "    labels = ['<70', '70-80', '80-90', '>90']\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    return df\n",
        "\n",
        "# === Bootstrap EOD CI only ===\n",
        "def bootstrap_eod(y_true, y_pred, sensitive_features, n_iterations=100):\n",
        "    eods = []\n",
        "    data = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'sensitive': sensitive_features})\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        sample = data.sample(frac=1.0, replace=True)\n",
        "        try:\n",
        "            eod = equalized_odds_difference(sample['y_true'], sample['y_pred'], sensitive_features=sample['sensitive'])\n",
        "            eods.append(eod)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if len(eods) == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    return (\n",
        "        np.nanpercentile(eods, 2.5),\n",
        "        np.nanpercentile(eods, 97.5)\n",
        "    )\n",
        "\n",
        "# === Apply age binning ===\n",
        "possible = bin_age(possible)\n",
        "\n",
        "# === Demographic groups ===\n",
        "demographic_groups = ['age_group', 'gender', 'insurance_group', 'language_group',\n",
        "                      'race_group1', 'race_group2', 'race_group3', 'race_group4']\n",
        "\n",
        "# === Run analysis for Train and Test ===\n",
        "data=possible\n",
        "records = []\n",
        "\n",
        "for group in demographic_groups:\n",
        "    if group not in data.columns:\n",
        "        continue\n",
        "\n",
        "    sensitive = data[group]\n",
        "    valid = sensitive.notna()\n",
        "    y_true = data.loc[valid, 'case_status']\n",
        "    y_pred = data.loc[valid, 'pred']\n",
        "    sensitive_group = sensitive[valid]\n",
        "\n",
        "    if len(sensitive_group.unique()) < 2:\n",
        "        continue  # skip if only one group value\n",
        "\n",
        "    # Compute EOD CI\n",
        "    eod_low, eod_high = bootstrap_eod(y_true, y_pred, sensitive_group)\n",
        "\n",
        "    records.append({\n",
        "        'Group': group,\n",
        "        'Equalized Odds Difference (95% CI)': f\"{eod_low:.3f}–{eod_high:.3f}\",\n",
        "        'Sample Size': len(sensitive_group),\n",
        "        'Flag (EOD > 0.1)': '⚠️' if eod_low > 0.1 else ''\n",
        "    })\n",
        "\n",
        "# Create and display results\n",
        "df_metrics = pd.DataFrame(records)\n",
        "df_metrics.set_index('Group', inplace=True)\n",
        "\n",
        "print(f\"\\n=== Equalized Odds Report ===\")\n",
        "print(df_metrics)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
