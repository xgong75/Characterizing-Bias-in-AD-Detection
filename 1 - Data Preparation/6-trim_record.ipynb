{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Z4LSeVZf94e0"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"01Rw4n9v53jj"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["data=pd.read_csv('11_final_cohort_alldata.csv.gz')\n","data.head()"],"metadata":{"id":"HRgKiQH36AqW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# fact check"],"metadata":{"id":"Z4LSeVZf94e0"}},{"cell_type":"code","source":["# prompt: check if there's any subject_id that have record charttime after charttime of the row's with ad=1\n","\n","import pandas as pd\n","\n","# Assuming 'data' DataFrame is already loaded as in the previous code snippet.\n","# If not, load it first:\n","# data = pd.read_csv('11_final_cohort_alldata.csv.gz')\n","\n","# Convert 'charttime' to datetime objects if it's not already\n","data['storetime'] = pd.to_datetime(data['storetime'])\n","\n","# Find rows where ad=1\n","ad_rows = data[data['ad'] == 1]\n","\n","# Check if any subject_id has a record with a later charttime than any of the ad=1 rows for the same subject_id.\n","for subject_id in data['subject_id'].unique():\n","  subject_data = data[data['subject_id'] == subject_id]\n","  ad_subject_data = ad_rows[ad_rows['subject_id'] == subject_id]\n","  if not ad_subject_data.empty:\n","    max_ad_charttime = ad_subject_data['storetime'].max()\n","    if any(subject_data['storetime'] > max_ad_charttime):\n","      print(f\"Subject ID {subject_id} has records after the latest storetime of ad=1 rows.\")\n","\n"],"metadata":{"id":"arcbVXJj7lBn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(data[\"subject_id\"].unique())"],"metadata":{"id":"I744jNtw6Hve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["notes=pd.read_csv('10_final_cohort_notes.csv.gz')\n","notes.head()"],"metadata":{"id":"sQJYqF_77KBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["notes[\"note_type\"].value_counts()"],"metadata":{"id":"Kvux4B_m7ndT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: give me the all rows with one subject_id have at least one row AD=1\n","\n","import pandas as pd\n","\n","# Group by subject_id and check if any 'ad' value is 1 within each group\n","subject_ad_check = data.groupby('subject_id')['ad'].any()\n","\n","# Get the subject_ids where at least one 'ad' value is 1\n","subject_ids_with_ad = subject_ad_check[subject_ad_check == True].index\n","\n","# Filter the original DataFrame to include only rows where subject_id is in the list above\n","ad_df = data[data['subject_id'].isin(subject_ids_with_ad)]\n","\n","ad_df"],"metadata":{"id":"6MOrgO3V_Kce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["person=ad_df[ad_df[\"subject_id\"]==10002131].sort_values([\"note_seq\"])\n","person"],"metadata":{"id":"mKhJSMNNAJR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["person.iloc[1,:][\"text\"]"],"metadata":{"id":"K9dbdtGsFN78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: give me an example of a subject_id with all rows ad=0 but case_status=1\n","\n","# Assuming 'data' DataFrame is already loaded as in the previous code snippet.\n","# If not, load it first:\n","# data = pd.read_csv('11_final_cohort_alldata.csv.gz')\n","\n","# Find subject_ids where all 'ad' values are 0 but 'case_status' is 1\n","result = data.groupby('subject_id').agg({'ad': 'max', 'case_status': 'max'})\n","target_subjects = result[(result['ad'] == 0) & (result['case_status'] == 1)].index.tolist()\n","\n","# Print the subject IDs that meet the criteria\n","if target_subjects:\n","  print(f\"Subject IDs with all 'ad' values equal to 0 and 'case_status' equal to 1:\\n{target_subjects}\")\n","else:\n","  print(\"No subjects found that meet the criteria.\")\n"],"metadata":{"id":"njSp-892_uy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["person_nonote=data[data[\"subject_id\"]==10348850].sort_values([\"note_seq\"])\n","person_nonote"],"metadata":{"id":"hDzRyF8ECZGf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["person_nonote.iloc[0,:][\"text\"]"],"metadata":{"id":"_97_kqa8HF87"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = data.sort_values(by=['subject_id', 'note_seq']).reset_index(drop=True)"],"metadata":{"id":"Trqy_cNUKpPv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: give me another person (person3) with AD in their first ever note\n","\n","import pandas as pd\n","\n","# Group by subject_id and get the first note for each subject\n","first_notes = data.groupby('subject_id').first().reset_index()\n","\n","# Find the first subject with AD in their first note\n","person3 = first_notes[first_notes['ad'] == 1]\n","\n","# Print the text of the first note for the third person with AD\n","print(person3)\n"],"metadata":{"id":"V_0ip8TPKaEr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[data[\"subject_id\"]==10015785].iloc[0][\"text\"]"],"metadata":{"id":"fvT9AAKoK7fO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Trim dataset"],"metadata":{"id":"WkTv98oVKWaE"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Assuming 'data' DataFrame is already loaded as in the previous code snippet.\n","# If not, load it first:\n","# data = pd.read_csv('11_final_cohort_alldata.csv.gz')\n","\n","# Create the two dataframes based on 'case_status'\n","case_status_1 = data[data['case_status'] == 1]\n","case_status_0 = data[data['case_status'] == 0]\n","\n","# Now you have two separate DataFrames:\n","# case_status_1: Contains rows where case_status is 1\n","# case_status_0: Contains rows where case_status is 0\n","\n","# You can now work with these DataFrames individually.  For example, to display the first few rows:\n","print(\"DataFrame with case_status = 1:\")\n","print(len(case_status_1[\"subject_id\"].unique()))\n","\n","print(\"\\nDataFrame with case_status = 0:\")\n","print(len(case_status_0[\"subject_id\"].unique()))\n"],"metadata":{"id":"aVozLMMLHdaM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["case_status_1_sorted = case_status_1.sort_values(by=['subject_id', 'note_seq']).reset_index(drop=True)"],"metadata":{"id":"hR9k80EEIhOW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Group data by subject_id\n","grouped = case_status_1_sorted.groupby('subject_id')\n","\n","# Function to filter rows within each group\n","def filter_rows(group):\n","  ad_indices = group[group['ad'] == 1].index\n","  if not ad_indices.empty:\n","    first_ad_index = ad_indices.min()\n","    return group.loc[:first_ad_index-1]\n","  else:\n","    return group\n","\n","# Apply the function to each group\n","filtered_data = grouped.apply(filter_rows)\n","\n","# Reset index if needed\n","filtered_data = filtered_data.reset_index(drop=True)\n","\n","filtered_data"],"metadata":{"id":"faChc6vAHtVt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### check how many patients we have left"],"metadata":{"id":"V1_VxfkwLyZO"}},{"cell_type":"code","source":["len(filtered_data['subject_id'].unique())"],"metadata":{"id":"g0Q0BSkuJjGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_concat = filtered_data.groupby('subject_id')['text'].apply(lambda x: '\\nNew Note:\\n'.join(x)).rename('text').reset_index()"],"metadata":{"id":"2Z6rgH0vNeTr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_concat"],"metadata":{"id":"Vwzdl9XbNget"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_concat.iloc[0][\"text\"]"],"metadata":{"id":"1hdNHsQbP8pm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build final dataset"],"metadata":{"id":"mKsSMwTOMkXX"}},{"cell_type":"code","source":["# Then, take the max of all other columns (excluding 'text')\n","other_max = data.drop(columns='text').groupby('subject_id').max().reset_index()\n","\n","# Combine both into one DataFrame\n","df_grouped = pd.merge(other_max, text_concat, on='subject_id', how='left', indicator=True)\n","\n","# View result\n","df_grouped"],"metadata":{"id":"2IH6ANLFMFrh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## double check"],"metadata":{"id":"rkXHH9LjOSsF"}},{"cell_type":"code","source":["len(df_grouped[df_grouped[\"_merge\"]==\"both\"])"],"metadata":{"id":"YYWNJBQKOD2A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df_grouped[df_grouped[\"case_status\"]==1])"],"metadata":{"id":"Bcnz_SUgOVQE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df_grouped[df_grouped[\"case_status\"]==0])"],"metadata":{"id":"1LecVhBROmYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_grouped.to_csv(\"trimed_dataset_perid.csv\")"],"metadata":{"id":"ayxaoaCLOznV"},"execution_count":null,"outputs":[]}]}