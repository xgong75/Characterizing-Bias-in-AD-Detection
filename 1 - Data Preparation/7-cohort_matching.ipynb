{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U37g5LiudHz_",
        "outputId": "2b108a5e-4477-4cf6-e48f-ac2c552d4f0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the gzipped CSV directly\n",
        "df = pd.read_csv('demographics_all_v3.csv.gz', compression='gzip')\n",
        "\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cawEzsopM75Y",
        "outputId": "d7cb72ed-42c9-4ba4-9b12-9ec9e768b04c"
      },
      "outputs": [],
      "source": [
        "#1584 unique patients\n",
        "len(df[df[\"ad_only\"]==1]['subject_id'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "6qpwqOnENNtQ",
        "outputId": "b90a1edc-6239-434c-e2b4-72414ca2a372"
      },
      "outputs": [],
      "source": [
        "# Filter for ad_only == 1\n",
        "ad_only_df = df[df[\"ad_only\"] == 1]\n",
        "\n",
        "# Group by subject_id and count the number of rows for each subject\n",
        "subject_counts = ad_only_df.groupby('subject_id')[\"hadm_id\"].count()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Display the distribution of row counts\n",
        "plt.hist(subject_counts,bins=100)\n",
        "plt.title(\"treatment patient entries\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xql0VJ7uYpTq",
        "outputId": "caedec71-f690-4aef-ed48-ee3e591eaa66"
      },
      "outputs": [],
      "source": [
        "# Assuming 'subject_counts' is the pandas Series you created earlier\n",
        "cutoff = np.percentile(subject_counts, 95)\n",
        "print(f\"The 95th percentile cutoff is: {cutoff}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAdYQ_K8OanJ",
        "outputId": "d8bbe118-3dac-4e2b-db6e-f8af1e15e36b"
      },
      "outputs": [],
      "source": [
        "subjects_multiple_rows = subject_counts[subject_counts > 1].index\n",
        "\n",
        "# Print the first 5 such subjects\n",
        "for subject_id in subjects_multiple_rows[:5]:\n",
        "    print(f\"Rows for subject_id: {subject_id}\")\n",
        "    print(ad_only_df[ad_only_df['subject_id'] == subject_id])\n",
        "    print(\"-\" * 20)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "qLyaG5IOMl8t",
        "outputId": "28702917-811b-4538-e52a-21bbf45d7c92"
      },
      "outputs": [],
      "source": [
        "df['race_group'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "EXNYUnjINVPS",
        "outputId": "5976312b-596d-4d4c-fabd-8b338867f7a4"
      },
      "outputs": [],
      "source": [
        "df['admission_type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhNQCLbKa30j",
        "outputId": "15d39e7a-4e68-42d6-f0ba-993ea8292773"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "gj5zy5GNO7MH",
        "outputId": "320729e2-9559-4caf-a22c-fcce1e499b33"
      },
      "outputs": [],
      "source": [
        "# Filter for ad_only == 1\n",
        "control_df = df[df[\"ad_only\"] == 0]\n",
        "\n",
        "# Group by subject_id and count the number of rows for each subject\n",
        "subject_counts = control_df.groupby('subject_id')[\"hadm_id\"].count()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Display the distribution of row counts\n",
        "plt.hist(subject_counts,bins=100)\n",
        "plt.title(\"control patient entries\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeZzqrdEYi5M",
        "outputId": "c9ceb85d-9474-421e-8a46-f7eb8a3e3473"
      },
      "outputs": [],
      "source": [
        "# Assuming 'subject_counts' is the pandas Series you created earlier\n",
        "cutoff = np.percentile(subject_counts, 95)\n",
        "print(f\"The 95th percentile cutoff is: {cutoff}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "r9tlm80GhfLa"
      },
      "outputs": [],
      "source": [
        "treatment_col = \"ad_only\"\n",
        "covariates = [\"gender\", \"race_group\", \"age\",'admission_type',\"marital_status\", 'language_group', \"insurance\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BepbKVAmS9CH"
      },
      "source": [
        "## Clean dataframe so unique treatment group id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A5bpTg1SZqc",
        "outputId": "d6c9b096-7c4f-4eab-c62e-36d9f29c7bed"
      },
      "outputs": [],
      "source": [
        "# Create a copy to avoid modifying the original DataFrame\n",
        "new_df = df.copy()\n",
        "\n",
        "# Convert admission date to datetime for proper comparison\n",
        "new_df['admit_date'] = pd.to_datetime(new_df[['admityear', 'admitmonth', 'admitday']].rename(columns={\n",
        "    'admityear': 'year',\n",
        "    'admitmonth': 'month',\n",
        "    'admitday': 'day'\n",
        "}))\n",
        "\n",
        "# Function to process each group\n",
        "def process_group(group):\n",
        "    if group['ad_only'].iloc[0] == 1:\n",
        "        # Find row with earliest admission date\n",
        "        min_idx = group['admit_date'].idxmin()\n",
        "        # Keep only this row\n",
        "        group = group.loc[[min_idx]]\n",
        "    return group\n",
        "\n",
        "# Group by 'subject_id' and apply the function\n",
        "new_df = new_df.groupby('subject_id', group_keys=False).apply(process_group)\n",
        "\n",
        "# Drop the temporary date column if needed\n",
        "new_df = new_df.drop(columns=['admit_date'])\n",
        "\n",
        "# Reset index\n",
        "new_df = new_df.reset_index(drop=True)\n",
        "\n",
        "# Display the result\n",
        "print(new_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "wMwTd3-DaEgZ"
      },
      "outputs": [],
      "source": [
        "# prompt: for ad_only=0 rows, remove all rows if it's subject_id is in ad_only=1 dataframe\n",
        "\n",
        "ad_only_df=new_df[new_df[\"ad_only\"]==1]\n",
        "control_df=new_df[new_df[\"ad_only\"]==0]\n",
        "\n",
        "# Get subject IDs from the ad_only=1 DataFrame\n",
        "ad_only_subjects = ad_only_df['subject_id'].unique()\n",
        "\n",
        "# Filter out rows from the control DataFrame where subject_id is in ad_only_subjects\n",
        "control_df = control_df[~control_df['subject_id'].isin(ad_only_subjects)]\n",
        "\n",
        "new_df=pd.concat([ad_only_df, control_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANJlHH28aO_g",
        "outputId": "e125df1d-1e45-4d2d-8ce0-456953e201c5"
      },
      "outputs": [],
      "source": [
        "# prompt: check if there's duplicative subject_id\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
        "duplicate_subjects = ad_only_df[ad_only_df.duplicated(subset=['subject_id'], keep=False)]\n",
        "\n",
        "if not duplicate_subjects.empty:\n",
        "  print(\"Duplicate subject_ids found:\")\n",
        "  print(duplicate_subjects[['subject_id']])\n",
        "else:\n",
        "  print(\"No duplicate subject_ids found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p__xPWiNTdZg",
        "outputId": "7dfb18e5-e490-4829-dc05-748dcd0fc9d5"
      },
      "outputs": [],
      "source": [
        "len(new_df[new_df[\"ad_only\"]==1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJU1HKGga-9n"
      },
      "source": [
        "# covariate balance matching - DAME-FLAME\n",
        "\n",
        "\n",
        "When to use:\n",
        "\n",
        "You want to retain all data points but ensure covariates (e.g., age, education) have similar distributions across outcomes.\n",
        "\n",
        "Ideal for predictive modeling (e.g., training a classifier to predict Alzheimerâ€™s).\n",
        "\n",
        "Pros:\n",
        "\n",
        "- Retains all data.\n",
        "\n",
        "- Reduces bias without discarding samples.\n",
        "\n",
        "Cons:\n",
        "\n",
        "- Does not guarantee exact matches for causal inference.\n",
        "\n",
        "### Intro of package\n",
        "Flame:\n",
        "Begin with iteration 1 by matching units exactly on the entire set of covariates. Then ieratively drop least important covariates to match until the remaining set of covariates cannot be used to accurately predict the outcome on trianing set\n",
        "\n",
        "Dame:(Dynamic Almost-Matching Exact)\n",
        "switch to second good combination of features instead of eliminate one at a time\n",
        "\n",
        "Frame-Dame:\n",
        "Frame until a point then Dame\n",
        "\n",
        "| Feature               | dame-flame                                                                                 | pymatch (Propensity Score)                                     |\n",
        "|-----------------------|--------------------------------------------------------------------------------------------|-----------------------------------------------------------------|\n",
        "| **Matching Approach** | Almost exact matching on subsets of covariates using ML-guided iterative approach         | Propensity scores (logistic regression/CatBoost)               |\n",
        "| **Categorical Handling** | No encoding needed; matches raw discrete covariates directly                           | Requires one-hot/dummy encoding                                |\n",
        "| **Interpretability**  | Can match explicit covariate subsets (e.g., Age=65, Sex=Female)                          | Opaque propensity scores (0.23 vs. 0.25)                        |\n",
        "| **Bias Reduction**    | Prioritizes matches on outcome-predictive covariates via holdout training                 | Relies on correct propensity model specification                |\n",
        "| **Scalability**       | Optimized for high-cardinality categorical data                                           | Better for large datasets with continuous covariates           |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMRwf9RWbAuZ"
      },
      "outputs": [],
      "source": [
        "from dame_flame.matching import DAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "xZn_df_OE8uJ",
        "outputId": "36081ff2-09ce-4565-e9dd-29ca88cdcf0b"
      },
      "outputs": [],
      "source": [
        "# prompt: check null value of covariates in df\n",
        "\n",
        "# Check for null values in the specified covariates\n",
        "null_counts = df[covariates].isnull().sum()\n",
        "null_counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sKVFWmHFK0W"
      },
      "source": [
        "### Only do matching on non-null features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "aUWtn0-EEntV",
        "outputId": "6410becd-d776-42f6-9dce-003ea4d36405"
      },
      "outputs": [],
      "source": [
        "# Initialize DAME model\n",
        "covariates_selected = [\"gender\", \"race\", \"age\", 'admission_type']\n",
        "\n",
        "# For multiple categorical columns:\n",
        "cat_cols = ['gender', 'race','admission_type']\n",
        "\n",
        "df_selected=df[covariates_selected]\n",
        "df_selected[\"treated\"]=df[treatment_col]\n",
        "df_selected['outcome'] = 0 # Add dummy outcome (all zeros), cuz the FLAME-DAME requires outcome\n",
        "df_selected[cat_cols] = df_selected[cat_cols].apply(lambda x: pd.factorize(x)[0]) #convert features to integers\n",
        "\n",
        "df_selected.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWvOheD3GsYM"
      },
      "outputs": [],
      "source": [
        "# After running your model specification:\n",
        "model = DAME(\n",
        "    repeats=False,          # 1:1 matching (no reuse of controls)\n",
        "    early_stop_pe=0,        # Disable outcome-based stopping\n",
        ")\n",
        "\n",
        "model.fit(df_selected, treatment_column_name='treated',outcome_column_name='outcome')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "roWP9tvDMz22",
        "outputId": "aa02f093-72bf-43ae-863f-ae922361a8cd"
      },
      "outputs": [],
      "source": [
        "matched_data = model.predict(df_selected)\n",
        "matched_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "r4n9E7l8M2VB",
        "outputId": "51ba675d-71ff-484d-8108-669578cb8d6f"
      },
      "outputs": [],
      "source": [
        "# prompt: get the rows of df_selected with the same row index as in all_matched_data\n",
        "\n",
        "# Get the indices of the matched rows\n",
        "matched_indices = matched_data.index\n",
        "\n",
        "# Select rows from df_selected using these indices\n",
        "df_matched_selected = df.loc[matched_indices]\n",
        "\n",
        "# Now df_matched_selected contains the rows from df_selected that were matched\n",
        "# and have the same row index as in all_matched_data.\n",
        "df_matched_selected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "5Sg0BaHjNNb1",
        "outputId": "7476e129-f4f6-4472-809c-1a3a57916cbd"
      },
      "outputs": [],
      "source": [
        "df_matched_selected[\"adrd\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "Aqze8-DkVv_1",
        "outputId": "4c480aa1-c38e-47d7-a060-72daafa5d900"
      },
      "outputs": [],
      "source": [
        "df[\"adrd\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vdS0z7BpRVJG",
        "outputId": "151a86c4-8ae3-4b80-d72d-129f4ffb2cce"
      },
      "outputs": [],
      "source": [
        "# prompt: plot covariate distribution between adrd groups for each covariate in covariates list, do subplots and make the x labels vertical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df_matched_selected' and 'covariates' are defined as in the previous code\n",
        "\n",
        "fig, axes = plt.subplots(len(covariates), 1, figsize=(8, 6 * len(covariates)))\n",
        "\n",
        "for i, covariate in enumerate(covariates):\n",
        "    sns.histplot(data=df_matched_selected, x=covariate, hue=\"adrd\", kde=True, ax=axes[i], element=\"step\")\n",
        "    axes[i].set_xlabel(covariate, fontsize=12)\n",
        "    axes[i].set_ylabel(\"Density\", fontsize=12)\n",
        "    axes[i].tick_params(axis='x', rotation=90) # Rotate x-axis labels vertically\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('adrd_distr_covariate_distribution.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u54xd1kPUF0Z"
      },
      "outputs": [],
      "source": [
        "df_matched_selected.to_csv('matched_adrd_distr.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYysGKzZRIg-"
      },
      "source": [
        "# 1:1 matching\n",
        "\n",
        "AD_only: 1584 VS 1584\n",
        "\n",
        "When to use:\n",
        "\n",
        "You need causal comparability (e.g., estimating treatment effects or isolating outcome-specific associations).\n",
        "\n",
        "Critical for observational studies where unmeasured confounding is a risk.\n",
        "\n",
        "Methods:\n",
        "\n",
        "Exact Matching (for categorical covariates):\n",
        "\n",
        "Pros:\n",
        "\n",
        "- Creates directly comparable groups.\n",
        "\n",
        "- Mimics randomized controlled trials.\n",
        "\n",
        "Cons:\n",
        "\n",
        "- Discards unmatched data (sample loss).\n",
        "\n",
        "- Computationally intensive for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t6YoN_p5Z9xO",
        "outputId": "0cefef1e-fcf1-40b1-bf23-9c0b217865d9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, axes = plt.subplots(len(covariates), 1, figsize=(8, 6 * len(covariates)))\n",
        "\n",
        "for i, covariate in enumerate(covariates):\n",
        "    sns.histplot(data=new_df, x=covariate, hue=treatment_col, kde=True, ax=axes[i], element=\"step\")\n",
        "    axes[i].set_xlabel(covariate, fontsize=12)\n",
        "    axes[i].set_ylabel(\"Density\", fontsize=12)\n",
        "    axes[i].tick_params(axis='x', rotation=90) # Rotate x-axis labels vertically\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{treatment_col}_before_distribution.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIc4-u9QWZyK",
        "outputId": "919afab1-38ce-442a-8fa8-b347932075ff"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df2=new_df[covariates]\n",
        "df2[treatment_col]=new_df[treatment_col]\n",
        "\n",
        "# Encode categorical variables\n",
        "df2 = pd.get_dummies(df2, columns= [\"gender\", \"race_group\",'admission_type',\"marital_status\", 'language_group', \"insurance\"], drop_first=True)\n",
        "\n",
        "# Calculate propensity scores\n",
        "X = df2.drop(columns=[treatment_col])\n",
        "y = df2[treatment_col]\n",
        "\n",
        "ps_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "ps_model.fit(X, y)\n",
        "df2[\"propensity_score\"] = ps_model.predict_proba(X)[:, 1]\n",
        "df2[\"subject_id\"]=new_df[\"subject_id\"]\n",
        "\n",
        "# 1:1 matching with caliper\n",
        "treated = df2[df2[treatment_col] == 1]\n",
        "controls = df2[df2[treatment_col] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "qnowqnZtYIh0"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import BallTree\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def ultra_fast_1to1_matching_with_exclusion(treated, controls, caliper=0.2):\n",
        "    \"\"\"\n",
        "    Optimized 1:1 matching with no control reuse and exclusion of all rows\n",
        "    with the same subject_id when a control is matched.\n",
        "    \"\"\"\n",
        "    # Convert to numpy arrays for speed\n",
        "    treated_ps = treated[\"propensity_score\"].values.reshape(-1, 1)\n",
        "    control_ps = controls[\"propensity_score\"].values.reshape(-1, 1)\n",
        "    control_indices = controls.index.values\n",
        "    control_subject_ids = controls[\"subject_id\"].values  # Track subject_ids\n",
        "\n",
        "    # Standardize\n",
        "    scaler = StandardScaler()\n",
        "    treated_ps_std = scaler.fit_transform(treated_ps)\n",
        "    control_ps_std = scaler.transform(control_ps)\n",
        "\n",
        "    # Build BallTree for fast radius searches\n",
        "    tree = BallTree(control_ps_std)\n",
        "\n",
        "    # Track used controls with boolean array (faster than set)\n",
        "    used_controls = np.zeros(len(controls), dtype=bool)\n",
        "    matches = []\n",
        "\n",
        "    # Process in random order to avoid quality bias\n",
        "    rng = np.random.default_rng(42)\n",
        "    treated_order = rng.permutation(len(treated))\n",
        "\n",
        "    for i in treated_order:\n",
        "        ps = treated_ps_std[i]\n",
        "        # Find all potential matches within caliper (radius search)\n",
        "        match_indices = tree.query_radius([ps], r=caliper)[0]\n",
        "\n",
        "        # Mask for unused controls\n",
        "        available_mask = ~used_controls[match_indices]\n",
        "        available_indices = match_indices[available_mask]\n",
        "\n",
        "        if len(available_indices) > 0:\n",
        "            # Find closest available control (using numpy argmin)\n",
        "            distances = np.abs(control_ps_std[available_indices].flatten() - ps[0])\n",
        "            best_idx = available_indices[np.argmin(distances)]\n",
        "\n",
        "            # Mark ALL rows with this subject_id as used\n",
        "            matched_subject_id = control_subject_ids[best_idx]\n",
        "            used_controls[control_subject_ids == matched_subject_id] = True\n",
        "\n",
        "            matches.append({\n",
        "                'treated_idx': treated.index[i],\n",
        "                'control_idx': control_indices[best_idx]\n",
        "            })\n",
        "\n",
        "    return matches\n",
        "\n",
        "# Usage\n",
        "matches = ultra_fast_1to1_matching_with_exclusion(treated, controls, caliper=0.2)\n",
        "\n",
        "# Create matched dataset (vectorized operations)\n",
        "treated_matched = treated.loc[[m['treated_idx'] for m in matches]]\n",
        "controls_matched = controls.loc[[m['control_idx'] for m in matches]]\n",
        "matched_df = pd.concat([treated_matched, controls_matched])\n",
        "\n",
        "# Add pair IDs in one operation\n",
        "matched_df['pair_id'] = np.repeat(np.arange(len(matches)), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbMu9EkbiL6g",
        "outputId": "87e47061-d6c9-4ad1-d07e-8ca61b034301"
      },
      "outputs": [],
      "source": [
        "len(matched_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hb2Os5YdXr9",
        "outputId": "1c199ec3-9bac-4a76-f6ec-509007918a86"
      },
      "outputs": [],
      "source": [
        "# Check balance\n",
        "def check_balance(df, covariates):\n",
        "    balance = {}\n",
        "    for var in covariates:\n",
        "        if var in df.columns:\n",
        "            t_mean = df[df[treatment_col] == 1][var].mean()\n",
        "            c_mean = df[df[treatment_col] == 0][var].mean()\n",
        "            pooled_std = np.sqrt((df[df[treatment_col] == 1][var].var() +\n",
        "                                df[df[treatment_col] == 0][var].var()) / 2)\n",
        "            balance[var] = abs((t_mean - c_mean) / pooled_std)\n",
        "    return balance\n",
        "\n",
        "balance_report = check_balance(matched_df, covariates)\n",
        "print(\"Balance Report (SMD < 0.1 is good):\")\n",
        "for var, smd in balance_report.items():\n",
        "    print(f\"{var}: {smd:.3f}\")\n",
        "\n",
        "\n",
        "print(f\"\\nMatched {len(treated_matched)} treated to {len(controls_matched)} controls\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "TJcfmHE1Zg3u"
      },
      "outputs": [],
      "source": [
        "# prompt: get the rows of df_selected with the same row index as in all_matched_data\n",
        "\n",
        "# Get the indices of the matched rows\n",
        "matched_indices = matched_df.index\n",
        "\n",
        "# Select rows from df_selected using these indices\n",
        "df_matched_selected = new_df.loc[matched_indices]\n",
        "\n",
        "# Now df_matched_selected contains the rows from df_selected that were matched\n",
        "# and have the same row index as in all_matched_data.\n",
        "df_matched_selected\n",
        "df_matched_selected.to_csv(f'matched_{treatment_col}.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsyM0ntPZEIX",
        "outputId": "102a1456-80a4-4f56-e52e-2469a9751ff8"
      },
      "outputs": [],
      "source": [
        "print(df_matched_selected.head())\n",
        "print(len(df_matched_selected))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc08A4wPZ1iW",
        "outputId": "54d88245-64a2-4cc7-ea9a-43ebeb3281f8"
      },
      "outputs": [],
      "source": [
        "# prompt: check if there's duplicative value for subject_id\n",
        "\n",
        "# Assuming 'df' is your DataFrame as defined in the provided code.\n",
        "duplicate_subjects = df_matched_selected[df_matched_selected.duplicated(subset=['subject_id'], keep=False)]\n",
        "\n",
        "if not duplicate_subjects.empty:\n",
        "    print(\"Duplicate subject IDs found:\")\n",
        "    print(duplicate_subjects[['subject_id']])\n",
        "else:\n",
        "    print(\"No duplicate subject IDs found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoPTWbcEbsSg",
        "outputId": "ed7e24ee-fb44-45f0-e1c9-5aae9a1a75d2"
      },
      "outputs": [],
      "source": [
        "# prompt: check if df_matched_selected has duplicative index, if yes return index\n",
        "\n",
        "# Check for duplicate indices\n",
        "duplicate_indices = df_matched_selected.index[df_matched_selected.index.duplicated(keep=False)]\n",
        "\n",
        "if not duplicate_indices.empty:\n",
        "  print(\"Duplicated indices found:\")\n",
        "  print(duplicate_indices)\n",
        "else:\n",
        "  print(\"No duplicate indices found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KNhBXPXfZXzk",
        "outputId": "bb7e5fd8-21a4-40ad-82a1-85a5daf62832"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(len(covariates), 1, figsize=(8, 6 * len(covariates)))\n",
        "\n",
        "for i, covariate in enumerate(covariates):\n",
        "    sns.histplot(data=df_matched_selected, x=covariate, hue=treatment_col, kde=True, ax=axes[i], element=\"step\")\n",
        "    axes[i].set_xlabel(covariate, fontsize=12)\n",
        "    axes[i].set_ylabel(\"Density\", fontsize=12)\n",
        "    axes[i].tick_params(axis='x', rotation=90) # Rotate x-axis labels vertically\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{treatment_col}_after_distribution.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cJU1HKGga-9n"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
